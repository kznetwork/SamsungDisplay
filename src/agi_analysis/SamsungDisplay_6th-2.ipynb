{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ba489a53-aa41-4f0d-af2f-62aa380d21eb",
      "metadata": {
        "id": "ba489a53-aa41-4f0d-af2f-62aa380d21eb"
      },
      "source": [
        "# 『2과목』 LangChain 모듈"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f20f89f-7aff-45cd-9909-543f928258ec",
      "metadata": {
        "id": "0f20f89f-7aff-45cd-9909-543f928258ec"
      },
      "source": [
        "## Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28426142-6915-4684-8e10-bbea0a2b27df",
      "metadata": {
        "id": "28426142-6915-4684-8e10-bbea0a2b27df",
        "outputId": "2640be6e-0e1b-461f-e9e8-8910cd57c77a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: openai\n",
            "Version: 1.84.0\n",
            "Summary: The official Python library for the openai API\n",
            "Home-page: https://github.com/openai/openai-python\n",
            "Author: \n",
            "Author-email: OpenAI <support@openai.com>\n",
            "License: Apache-2.0\n",
            "Location: c:\\dev\\envs\\py3_10_langchain\\lib\\site-packages\n",
            "Requires: anyio, distro, httpx, jiter, pydantic, sniffio, tqdm, typing-extensions\n",
            "Required-by: langchain-openai\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip show openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72c5370f-df2c-424c-8dbc-bcc7ed66bf2a",
      "metadata": {
        "id": "72c5370f-df2c-424c-8dbc-bcc7ed66bf2a",
        "outputId": "3a47d57d-8824-441c-b794-c35a5ec4b9b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: langchain\n",
            "Version: 0.3.25\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: c:\\dev\\envs\\py3_10_langchain\\lib\\site-packages\n",
            "Requires: async-timeout, langchain-core, langchain-text-splitters, langsmith, pydantic, PyYAML, requests, SQLAlchemy\n",
            "Required-by: \n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip show langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac976171-025e-431a-848d-3302b1a23e40",
      "metadata": {
        "id": "ac976171-025e-431a-848d-3302b1a23e40"
      },
      "outputs": [],
      "source": [
        "# 환경변수 준비\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"proj-3n8TNE_rqiosOfKRsc_piZXDcFYq_RiDoKxVVQoMiOl7dVYJKwKqUbacavWtx2uNSNCDgokPRBT3BlbkFJkFPfkDexGj5Y_NFt2nz8mS6W6vpCL3CZ7ylCqPTyzeon7NnEoVuzi-Rs52gIDnn7F__pLFeA4A\"\n",
        "os.environ[\"OPENAI_API_KEY\"]\n",
        "\n",
        "import openai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d47034dd-382a-469b-a94d-9ef9fd613b0e",
      "metadata": {
        "id": "d47034dd-382a-469b-a94d-9ef9fd613b0e"
      },
      "source": [
        "## 『1장』 LangChain Expression Language(LCEL)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "549a81c0-ca23-4491-8427-ae33a68e8f8d",
      "metadata": {
        "id": "549a81c0-ca23-4491-8427-ae33a68e8f8d"
      },
      "source": [
        "### LangChain Expression Language(LCEL) 예제"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54a2cff4-9189-4211-b7f0-3101f2fcdf19",
      "metadata": {
        "id": "54a2cff4-9189-4211-b7f0-3101f2fcdf19"
      },
      "source": [
        "프롬프트 템플릿의 활용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6334b07f-fc7b-4f8e-816a-2b8561ef9d6d",
      "metadata": {
        "id": "6334b07f-fc7b-4f8e-816a-2b8561ef9d6d"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "066cbc1f-07b7-4b49-9cd6-129fe0572651",
      "metadata": {
        "id": "066cbc1f-07b7-4b49-9cd6-129fe0572651",
        "outputId": "d742e0ba-968a-49e4-e7b9-e1070152018d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='{country}의 수도는 어디인가요?')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# template 정의\n",
        "template = \"{country}의 수도는 어디인가요?\"\n",
        "\n",
        "# from_template 메소드를 이용하여 PromptTemplate 객체 생성\n",
        "prompt_template = PromptTemplate.from_template(template)\n",
        "prompt_template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d2c4ea3-8d2f-4438-aa05-b6f584228a1c",
      "metadata": {
        "id": "4d2c4ea3-8d2f-4438-aa05-b6f584228a1c",
        "outputId": "11e04e5f-11d6-4000-95eb-225c4022e763"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "대한민국의 수도는 어디인가요?\n"
          ]
        }
      ],
      "source": [
        "# Generate prompt for '대한민국'\n",
        "prompt = prompt_template.format(country=\"대한민국\")\n",
        "print(prompt)  # Check the generated prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ea32e31-75c9-43d4-8758-4ca8155315ba",
      "metadata": {
        "id": "2ea32e31-75c9-43d4-8758-4ca8155315ba",
        "outputId": "6d755259-31be-48e1-9c2f-60bd08a121e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "미국의 수도는 어디인가요?\n"
          ]
        }
      ],
      "source": [
        "# Generate prompt for '미국'\n",
        "prompt = prompt_template.format(country=\"미국\")\n",
        "print(prompt)  # Check the generated prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3b26d6a-b362-4518-a04c-b974063481ca",
      "metadata": {
        "id": "f3b26d6a-b362-4518-a04c-b974063481ca"
      },
      "outputs": [],
      "source": [
        "# Define a model with GPT-3.5-turbo and specific parameters\n",
        "model = ChatOpenAI(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    max_tokens=2048,\n",
        "    temperature=0.1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6649eb3-4cb8-4c51-a7eb-d2ed90cc8203",
      "metadata": {
        "id": "b6649eb3-4cb8-4c51-a7eb-d2ed90cc8203"
      },
      "source": [
        "Chain 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6a411f2-87f9-4102-9243-84bfbcb3e825",
      "metadata": {
        "id": "b6a411f2-87f9-4102-9243-84bfbcb3e825"
      },
      "outputs": [],
      "source": [
        "# Create a new PromptTemplate for explaining a topic\n",
        "prompt_template = PromptTemplate.from_template(\"{topic}에 대해 쉽게 설명해주세요.\")\n",
        "\n",
        "# Chain the prompt and model using the pipe operator\n",
        "chain = prompt_template | model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82ddacc3-7688-4688-ad61-619edf45891d",
      "metadata": {
        "id": "82ddacc3-7688-4688-ad61-619edf45891d"
      },
      "outputs": [],
      "source": [
        "# input 딕셔너리에 주제를 '인공지능 모델의 학습 원리'으로 설정합니다.\n",
        "input = {\"topic\": \"인공지능 모델의 학습 원리\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "783a4811-249e-4700-bbe1-f9ef215743fd",
      "metadata": {
        "id": "783a4811-249e-4700-bbe1-f9ef215743fd",
        "outputId": "ce966e60-6182-4062-c993-0c26e559c7d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='인공지능 모델의 학습 원리는 데이터를 입력으로 받아들이고, 이 데이터를 분석하여 패턴을 찾아내는 과정입니다. 모델은 입력된 데이터를 기반으로 가중치를 조정하고, 이를 통해 원하는 결과를 예측하거나 분류할 수 있습니다.\\n\\n학습 과정은 크게 지도학습, 비지도학습, 강화학습으로 나눌 수 있습니다. 지도학습은 입력 데이터와 정답 레이블이 함께 제공되어 모델이 정확한 결과를 예측하도록 학습하는 방식이며, 비지도학습은 정답 레이블 없이 데이터의 패턴을 찾아내는 방식입니다. 강화학습은 환경과 상호작용하며 보상을 최대화하는 방향으로 학습하는 방식입니다.\\n\\n이러한 학습 원리를 통해 인공지능 모델은 데이터를 분석하고 패턴을 찾아내어 다양한 작업을 수행할 수 있습니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 311, 'prompt_tokens': 33, 'total_tokens': 344, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BedP22cTWajh0EV1zZ91Odk9TJls7', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--fcb71c05-56df-4fb2-a52a-39ba2de5bd21-0' usage_metadata={'input_tokens': 33, 'output_tokens': 311, 'total_tokens': 344, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
          ]
        }
      ],
      "source": [
        "# prompt 객체와 model 객체를 파이프(|) 연산자로 연결하고 invoke 메서드를 사용하여 input을 전달합니다.\n",
        "# 이를 통해 AI 모델이 생성한 메시지를 반환합니다.\n",
        "response = chain.invoke(input)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34d753f0-813f-44a9-9fad-0d720f976614",
      "metadata": {
        "id": "34d753f0-813f-44a9-9fad-0d720f976614",
        "outputId": "9d0aacb0-0684-4e6a-d836-8c8b5e6ed873",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='인' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='공' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='지' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='능' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 모' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='델' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='의' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 학' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='습' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 원' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='리' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='는' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 데이터' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='를' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 입력' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='으로' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 받' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='아' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='들' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='이' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='고' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=',' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 이' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 데이터' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='를' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 분' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='석' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='하여' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 패' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='턴' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='을' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 학' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='습' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='하는' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 과' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='정' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='입니다' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='.' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 이' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 과' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='정' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='은' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 크' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='게' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 입력' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='층' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=',' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 은' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='닉' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='층' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=',' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 출력' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='층' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='으로' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 구' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='성' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='된' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 인' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='공' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='신' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='경' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='망' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='을' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 사용' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='하여' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 이' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='루' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='어' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='집' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='니다' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='.\\n\\n' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='먼' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='저' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=',' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 입력' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='층' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='에서' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 모' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='델' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='에' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 데이터' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='가' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 입력' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='되' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='고' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=',' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 이' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 데이터' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='는' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 은' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='닉' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='층' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='을' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 거' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='쳐' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 출력' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='층' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='으로' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 전' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='달' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='됩니다' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='.' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 은' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='닉' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='층' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='은' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 입력' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='층' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='의' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 데이터' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='를' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 가' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='중' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='치' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='와' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 편' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='향' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='을' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 조' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='절' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='하여' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 적' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='절' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='한' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 형' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='태' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='로' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 변' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='환' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='하는' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 역' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='할' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='을' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 합니다' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='.' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 출력' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='층' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='에서' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='는' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 최' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='종' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='적' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='인' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 결과' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='를' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 출력' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='하' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='게' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 됩니다' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='.\\n\\n' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='이' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='때' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=',' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 모' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='델' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='은' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 입력' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 데이터' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='와' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 실' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='제' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 결과' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 사' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='이' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='의' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 차' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='이' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='를' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 최' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='소' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='화' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='하는' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 방' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='향' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='으로' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 가' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='중' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='치' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='와' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 편' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='향' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='을' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 조' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='정' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='하' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='면' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='서' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 학' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='습' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='을' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 진' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='행' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='합니다' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='.' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 이' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 과' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='정' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='을' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 반' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='복' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='하' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='면' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='서' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 모' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='델' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='은' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 데이터' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='의' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 패' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='턴' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='을' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 학' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='습' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='하' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='고' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=',' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 새' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='로' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='운' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 데이터' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='가' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 입력' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='되' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='었' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='을' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 때' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 정' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='확' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='한' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 결과' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='를' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 예' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='측' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='할' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 수' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 있' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='게' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content=' 됩니다' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='.' additional_kwargs={} response_metadata={} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125', 'service_tier': 'default'} id='run--155e97a7-1420-4e1b-97fd-4168a42a268b'"
          ]
        }
      ],
      "source": [
        "# Stream the output\n",
        "answer = chain.stream(input)\n",
        "\n",
        "# Handle streaming response (You need to replace or define this part)\n",
        "for chunk in answer:\n",
        "    print(chunk, end=\"\", flush=True)  # Streaming output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3ba75d8-1576-453e-b94f-7e1f333cb9bc",
      "metadata": {
        "id": "d3ba75d8-1576-453e-b94f-7e1f333cb9bc"
      },
      "source": [
        "출력파서(Output Parser)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53b3511b-828e-4c6b-931b-379ae2676e68",
      "metadata": {
        "id": "53b3511b-828e-4c6b-931b-379ae2676e68"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "output_parser = StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f743fd3e-63b8-4e2a-8edc-bc27c355367c",
      "metadata": {
        "id": "f743fd3e-63b8-4e2a-8edc-bc27c355367c"
      },
      "outputs": [],
      "source": [
        "# 프롬프트, 모델, 출력 파서를 연결하여 처리 체인을 구성합니다.\n",
        "chain = prompt_template | model | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f031c234-14a4-49a2-b323-5a13294aea43",
      "metadata": {
        "id": "f031c234-14a4-49a2-b323-5a13294aea43",
        "outputId": "2be2def9-d12e-433a-b15d-a52949ba3a10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "인공지능 모델의 학습 원리는 데이터를 입력으로 받아들이고, 이 데이터를 분석하여 패턴이나 규칙을 학습하는 과정입니다. 이를 위해 모델은 입력 데이터를 처리하고, 출력을 생성하며, 이 출력을 기반으로 오차를 계산하여 자신을 업데이트합니다. 이 과정을 반복하면서 모델은 점차적으로 더 나은 성능을 발휘하도록 학습하게 됩니다. 이러한 학습 원리를 통해 인공지능 모델은 주어진 데이터에 대해 판단하고 예측하는 능력을 향상시킬 수 있습니다.\n"
          ]
        }
      ],
      "source": [
        "# chain 객체의 invoke 메서드를 사용하여 input을 전달합니다.\n",
        "input = {\"topic\": \"인공지능 모델의 학습 원리\"}\n",
        "response = chain.invoke(input)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9850030-045f-4e03-ae58-5e24e5639ee4",
      "metadata": {
        "id": "d9850030-045f-4e03-ae58-5e24e5639ee4",
        "outputId": "6e4e9892-7b68-4769-f37b-15d7b6badaa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "인공지능 모델의 학습 원리는 데이터를 입력으로 받아들이고, 이 데이터를 분석하여 패턴을 찾아내는 과정입니다. 이 과정은 크게 입력층, 은닉층, 출력층으로 구성된 인공신경망을 사용하여 이루어집니다.\n",
            "\n",
            "먼저, 입력층에는 데이터가 입력되고, 이 데이터는 은닉층을 거쳐 출력층으로 전달됩니다. 은닉층은 입력층과 출력층 사이에 위치하며, 입력된 데이터를 가중치와 편향을 곱하고 활성화 함수를 적용하여 새로운 값으로 변환합니다.\n",
            "\n",
            "이렇게 변환된 값은 출력층에서 최종 결과를 출력하게 되는데, 이 결과를 기반으로 모델이 학습을 진행합니다. 학습 과정에서 모델은 입력된 데이터와 실제 결과값을 비교하여 오차를 계산하고, 이 오차를 최소화하는 방향으로 가중치와 편향을 조정하며 학습을 진행합니다.\n",
            "\n",
            "이러한 과정을 반복하면서 모델은 데이터의 패턴을 학습하고, 새로운 데이터가 입력되었을 때 정확한 결과를 예측할 수 있도록 학습됩니다. 이렇게 학습된 모델은 다양한 분야에서 활용되어 문제를 해결하거나 예측하는 데 도움을 줄 수 있습니다."
          ]
        }
      ],
      "source": [
        "# Stream the output\n",
        "answer = chain.stream(input)\n",
        "\n",
        "# Handle streaming response (You need to replace or define this part)\n",
        "for chunk in answer:\n",
        "    print(chunk, end=\"\", flush=True)  # Streaming output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4e96dee-aa86-4af4-8b34-effd17e068d1",
      "metadata": {
        "id": "e4e96dee-aa86-4af4-8b34-effd17e068d1"
      },
      "source": [
        "템플릿을 변경하여 적용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cf44181-56ca-412f-b6c3-aec716196b22",
      "metadata": {
        "id": "4cf44181-56ca-412f-b6c3-aec716196b22"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"\n",
        "당신은 영어를 가르치는 10년차 영어 선생님입니다. 상황에 [FORMAT]에 영어 회화를 작성해 주세요.\n",
        "\n",
        "상황:\n",
        "{question}\n",
        "\n",
        "FORMAT:\n",
        "- 영어 회화:\n",
        "- 한글 해석:\n",
        "\"\"\"\n",
        "\n",
        "# 프롬프트 템플릿을 이용하여 프롬프트를 생성합니다.\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "# ChatOpenAI 챗모델을 초기화합니다.\n",
        "model = ChatOpenAI(model_name=\"gpt-4-turbo\")\n",
        "\n",
        "# 문자열 출력 파서를 초기화합니다.\n",
        "output_parser = StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b0e02e2-3e66-426f-b6bf-2e49c6422979",
      "metadata": {
        "id": "3b0e02e2-3e66-426f-b6bf-2e49c6422979"
      },
      "outputs": [],
      "source": [
        "# 체인을 구성합니다.\n",
        "chain = prompt | model | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6e49325-5e4f-473b-9f31-576854f13eda",
      "metadata": {
        "id": "c6e49325-5e4f-473b-9f31-576854f13eda",
        "outputId": "54532d19-25e8-4934-9581-daebf411c056"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "영어 회화:\n",
            "- Hello! Could I see the menu, please?\n",
            "- Yes, of course. Here you are.\n",
            "- Thank you. I’d like to order the grilled salmon and a side of mashed potatoes.\n",
            "- Sure thing. Would you like anything to drink?\n",
            "- Yes, I'll have a glass of white wine, please.\n",
            "- Great choice! I'll bring your drink right away and your meal will be ready shortly.\n",
            "\n",
            "한글 해석:\n",
            "- 안녕하세요! 메뉴판 좀 볼 수 있을까요?\n",
            "- 네, 물론입니다. 여기 있습니다.\n",
            "- 감사합니다. 그릴드 연어와 매시드 포테이토를 주문하고 싶어요.\n",
            "- 알겠습니다. 음료는 드릴까요?\n",
            "- 네, 화이트 와인 한 잔 주세요.\n",
            "- 좋은 선택이네요! 음료는 바로 가져다 드리고, 식사는 곧 준비될 거예요."
          ]
        }
      ],
      "source": [
        "# 완성된 Chain을 실행하여 답변을 얻습니다.\n",
        "# 스트리밍 출력을 위한 요청\n",
        "answer = chain.stream({\"question\": \"저는 식당에 가서 음식을 주문하고 싶어요\"})\n",
        "# 스트리밍 출력\n",
        "# Handle streaming response (You need to replace or define this part)\n",
        "for chunk in answer:\n",
        "    print(chunk, end=\"\", flush=True)  # Streaming output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4b939b5-f581-488a-ae73-4ce3a6360b47",
      "metadata": {
        "id": "a4b939b5-f581-488a-ae73-4ce3a6360b47",
        "outputId": "ee4af84a-0b14-4779-a2a4-3e4c2a2f55b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "영어 회화:\n",
            "- Hello, I'd like to order a pizza for delivery, please.\n",
            "- Sure, what size are you looking for and what toppings would you like on your pizza?\n",
            "- I'd like a large pizza with pepperoni, mushrooms, and extra cheese.\n",
            "- Anything else?\n",
            "- Yes, can I also get a side of garlic bread and a 2-liter bottle of Coke?\n",
            "- Absolutely, can I have your delivery address?\n",
            "- It's 742 Evergreen Terrace. How long will the delivery take?\n",
            "- It should be there in about 30-40 minutes.\n",
            "- Great, thank you!\n",
            "- Thank you for your order. Enjoy your meal!\n",
            "\n",
            "한글 해석:\n",
            "- 안녕하세요, 배달로 피자 주문하고 싶습니다.\n",
            "- 네, 어떤 크기를 원하시고 토핑은 무엇으로 하시겠습니까?\n",
            "- 대형 피자에 페퍼로니, 버섯, 그리고 추가 치즈를 올려주세요.\n",
            "- 추가로 더 필요한 것이 있으신가요?\n",
            "- 네, 마늘빵 하나와 콜라 2리터도 같이 주문할게요.\n",
            "- 알겠습니다, 배달 주소를 알려주실 수 있나요?\n",
            "- 742 에버그린 테라스입니다. 배달은 얼마나 걸리나요?\n",
            "- 약 30-40분 내에 배달될 예정입니다.\n",
            "- 좋습니다, 감사합니다!\n",
            "- 주문해 주셔서 감사합니다. 맛있게 드세요!"
          ]
        }
      ],
      "source": [
        "# 이번에는 question 을 '미국에서 피자 주문'으로 설정하여 실행합니다.\n",
        "# 스트리밍 출력을 위한 요청\n",
        "answer = chain.stream({\"question\": \"미국에서 피자 주문\"})\n",
        "# Handle streaming response (You need to replace or define this part)\n",
        "for chunk in answer:\n",
        "    print(chunk, end=\"\", flush=True)  # Streaming output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbbf4fe5-1c0a-43e9-bbbc-8336b26536bf",
      "metadata": {
        "id": "dbbf4fe5-1c0a-43e9-bbbc-8336b26536bf"
      },
      "source": [
        "### LCEL 인터페이스"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0438356-e1f3-4866-a0f8-e34e74efe6ec",
      "metadata": {
        "id": "c0438356-e1f3-4866-a0f8-e34e74efe6ec"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# ChatOpenAI 모델을 인스턴스화합니다.\n",
        "model = ChatOpenAI()\n",
        "# 주어진 토픽에 대한 농담을 요청하는ㅁㅊ 프롬프트 템플릿을 생성합니다.\n",
        "prompt = PromptTemplate.from_template(\"{topic} 에 대하여 3문장으로 설명해줘.\")\n",
        "# 프롬프트와 모델을 연결하여 대화 체인을 생성합니다.\n",
        "chain = prompt | model | StrOutputParser()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e28431b5-389b-4a24-b15e-9106108be89a",
      "metadata": {
        "id": "e28431b5-389b-4a24-b15e-9106108be89a"
      },
      "source": [
        "#### Stream"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c527a16-2068-407a-bbf7-8ab9c27f187a",
      "metadata": {
        "id": "7c527a16-2068-407a-bbf7-8ab9c27f187a",
        "outputId": "ca690d59-9eaf-4efa-df92-6c95265b2725"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "멀티모달은 여러 가지 다른 형태의 미디어를 조합하여 정보를 전달하는 방식을 말합니다. 이는 텍스트, 이미지, 동영상, 음성 등 다양한 형태의 자료를 모아 하나의 메시지로 전달하는 것을 의미합니다. 멀티모달은 사람들에게 다양한 감각을 자극하여 정보를 더욱 효과적으로 전달하고 이해를 돕는 역할을 합니다."
          ]
        }
      ],
      "source": [
        "# chain.stream 메서드를 사용하여 '멀티모달' 토픽에 대한 스트림을 생성하고 반복합니다.\n",
        "for token in chain.stream({\"topic\": \"멀티모달\"}):\n",
        "    # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
        "    print(token, end=\"\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4699ee61-b7ec-47dc-81a5-629914679ef0",
      "metadata": {
        "id": "4699ee61-b7ec-47dc-81a5-629914679ef0"
      },
      "source": [
        "#### Invoke"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "baa00d08-4e04-41ef-ab4b-d36f1223dee3",
      "metadata": {
        "id": "baa00d08-4e04-41ef-ab4b-d36f1223dee3",
        "outputId": "be5791ea-d4fc-4f44-f1ab-ae34238cdc7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'ChatGPT는 인공지능 챗봇으로, 사용자와 대화를 나누어 질문에 대한 답변이나 정보를 제공합니다. 감정을 이해하고 자연스러운 대화를 진행하여 사용자에게 편리함을 제공합니다. 다양한 주제에 대해 학습하고 지식을 제공하며, 상황에 맞는 유용한 정보를 제공합니다.'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# chain 객체의 invoke 메서드를 호출하고, 'ChatGPT'라는 주제로 딕셔너리를 전달합니다.\n",
        "chain.invoke({\"topic\": \"ChatGPT\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43577c2d-c2d7-406c-bf67-6a1cc13ed92e",
      "metadata": {
        "id": "43577c2d-c2d7-406c-bf67-6a1cc13ed92e"
      },
      "source": [
        "#### Batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "996cc598-9322-4203-b954-64b86453d09a",
      "metadata": {
        "id": "996cc598-9322-4203-b954-64b86453d09a",
        "outputId": "25b8cd49-be80-46f6-8e0c-990309ef17d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ChatGPT는 OpenAI에서 개발한 대화형 인공지능 모델로, 자연어 처리 기술을 활용하여 다양한 주제에 대해 대화를 나눌 수 있습니다. 사용자의 질문에 정확하고 자연스러운 답변을 제공하며, 학습을 통해 점차적으로 더 나은 대화 능력을 갖추고 있습니다. 다양한 분야에서 유용하게 활용되며, 현대 기술의 대표적인 사례 중 하나로 인정받고 있습니다.',\n",
              " 'Instagram은 사진과 동영상을 공유할 수 있는 소셜 미디어 플랫폼이다. 사용자들은 자신의 일상, 취향, 관심사 등을 시각적으로 공유할 수 있으며, 팔로워와 소통하며 커뮤니케이션할 수 있다. 인기 있는 인플루언서와 브랜드들이 활발하게 활동하며 시장에서 큰 영향력을 발휘하고 있다.']"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 주어진 토픽 리스트를 batch 처리하는 함수 호출\n",
        "chain.batch([{\"topic\": \"ChatGPT\"}, {\"topic\": \"Instagram\"}])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6094238f-0e54-4e78-abb6-41446f3ea6bd",
      "metadata": {
        "id": "6094238f-0e54-4e78-abb6-41446f3ea6bd",
        "outputId": "ebd43c7a-224b-44bf-d89d-6a1dfd63443a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ChatGPT는 자연어 처리 기술을 사용하여 대화형 인공지능 챗봇을 만드는 플랫폼이다. 이를 통해 사용자들은 간단한 질문부터 복잡한 주제에 대한 대화를 할 수 있으며, 다양한 분야에서 적용할 수 있다. ChatGPT는 문장 생성, 감정 분석, 요약 등 다양한 기능을 제공하여 실용적이고 혁신적인 대화형 서비스를 구축할 수 있다.',\n",
              " 'Instagram은 사진과 동영상을 공유할 수 있는 소셜 미디어 플랫폼이다. 사용자들은 팔로워들과 소통하며 일상을 공유하고, 다양한 필터와 효과를 이용하여 창의적인 콘텐츠를 제작할 수 있다. 또한 해시태그를 통해 특정 주제나 관심사에 관련된 게시물을 찾아볼 수 있다.',\n",
              " '멀티모달은 여러 가지 형태의 통신 방식을 조합하여 정보를 전송하는 방법을 말합니다. 예를 들어, 음성, 영상, 텍스트 등의 다양한 형태의 데이터를 동시에 활용하여 효율적으로 정보를 전달할 수 있습니다. 멀티모달은 사람들이 정보를 보다 쉽고 빠르게 이해하고 활용할 수 있도록 도와줍니다.',\n",
              " '프로그래밍은 컴퓨터에게 실행할 일련의 명령을 작성하는 과정이다. 이러한 명령들은 프로그래머가 원하는 작업을 수행하도록 도와준다. 프로그래밍 언어를 사용하여 문제를 해결하고 프로그램을 개발하는 것이 프로그래밍의 주요 목표이다.',\n",
              " '머신러닝은 컴퓨터 시스템이 데이터를 이용하여 스스로 학습하고 결정을 내리는 기술이다. 이를 통해 패턴을 발견하거나 예측을 수행할 수 있으며, 학습된 모델을 사용하여 다양한 문제를 해결할 수 있다. 머신러닝은 이미지 인식, 자연어 처리, 추천 시스템 등 다양한 분야에서 활발히 활용되고 있다.']"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.batch(\n",
        "    [\n",
        "        {\"topic\": \"ChatGPT\"},\n",
        "        {\"topic\": \"Instagram\"},\n",
        "        {\"topic\": \"멀티모달\"},\n",
        "        {\"topic\": \"프로그래밍\"},\n",
        "        {\"topic\": \"머신러닝\"},\n",
        "    ],\n",
        "    config={\"max_concurrency\": 3},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0274c50a-86cb-4875-987d-5f195d250253",
      "metadata": {
        "id": "0274c50a-86cb-4875-987d-5f195d250253"
      },
      "source": [
        "#### Async"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bfcbac2-3074-438a-b3f1-736dfe788af1",
      "metadata": {
        "id": "7bfcbac2-3074-438a-b3f1-736dfe788af1"
      },
      "source": [
        "Async Stream"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67c97a61-35f6-4c82-8989-7d88bd47f751",
      "metadata": {
        "id": "67c97a61-35f6-4c82-8989-7d88bd47f751",
        "outputId": "818666bc-e1e4-4088-e896-745febd6d53c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YouTube는 구글이 소유하고 있는 동영상 공유 플랫폼으로 사용자들이 영상을 업로드하고 시청할 수 있다. 전 세계적으로 매일 수십억 명의 사용자가 이용하며 다양한 콘텐츠를 제공한다. 유명인들부터 일반인들까지 누구나 동영상을 올릴 수 있어서 다양한 정보를 얻을 수 있다."
          ]
        }
      ],
      "source": [
        "# 비동기 스트림을 사용하여 'YouTube' 토픽의 메시지를 처리합니다.\n",
        "async for token in chain.astream({\"topic\": \"YouTube\"}):\n",
        "    # 메시지 내용을 출력합니다. 줄바꿈 없이 바로 출력하고 버퍼를 비웁니다.\n",
        "    print(token, end=\"\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcef3d8e-38b4-4afb-a17a-d2d80c4ff97e",
      "metadata": {
        "id": "dcef3d8e-38b4-4afb-a17a-d2d80c4ff97e"
      },
      "source": [
        "Async Invoke"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bb79ea9-0d92-4384-ad0e-eb6b0f28e96b",
      "metadata": {
        "id": "4bb79ea9-0d92-4384-ad0e-eb6b0f28e96b",
        "outputId": "7ac21696-9171-4d55-b95f-08840c037694"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'NVDA는 NVIDIA Corporation의 주식 코드이며, 전 세계적으로 선도적인 그래픽 처리 장치를 제조하는 기업으로 유명하다. 주로 게이밍, 자율주행 자동차 및 데이터 센터 분야에서 사용되는 그래픽 카드 및 인공지능 기술을 생산한다. NVDA 주식은 기술 산업에 대한 투자자들 사이에서 매우 인기가 높다.'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 비동기 체인 객체의 'ainvoke' 메서드를 호출하여 'NVDA' 토픽을 처리합니다.\n",
        "my_process = chain.ainvoke({\"topic\": \"NVDA\"})\n",
        "# 비동기로 처리되는 프로세스가 완료될 때까지 기다립니다.\n",
        "await my_process"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9199b247-29f3-45db-b730-d4cca3c6e581",
      "metadata": {
        "id": "9199b247-29f3-45db-b730-d4cca3c6e581"
      },
      "source": [
        "Async Batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4d56e89-e418-4d20-8559-efa4a68d00c3",
      "metadata": {
        "id": "c4d56e89-e418-4d20-8559-efa4a68d00c3"
      },
      "outputs": [],
      "source": [
        "# 주어진 토픽에 대해 비동기적으로 일괄 처리를 수행합니다.\n",
        "my_abatch_process = chain.abatch(\n",
        "    [{\"topic\": \"YouTube\"}, {\"topic\": \"Instagram\"}, {\"topic\": \"Facebook\"}]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb499fb4-5a5a-4665-b68c-eb0132e17f87",
      "metadata": {
        "id": "fb499fb4-5a5a-4665-b68c-eb0132e17f87",
        "outputId": "9c2ef732-a08b-4cab-89fd-bf7f378dcd3e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['YouTube는 전 세계에서 가장 인기 있는 동영상 공유 플랫폼으로, 사용자들은 다양한 주제의 동영상을 시청하고 업로드할 수 있다. 광고 수익과 구독자 수를 통해 크리에이터들은 수익을 창출할 수 있다. 다양한 콘텐츠를 제공하며 사용자들과 상호작용할 수 있는 댓글, 좋아요, 싫어요 등의 기능도 제공된다.',\n",
              " 'Instagram은 사진과 동영상을 공유하고, 다른 사람들의 글을 볼 수 있는 소셜 미디어 플랫폼이다. 사용자들은 다양한 필터와 효과를 이용하여 자신의 콘텐츠를 꾸밀 수 있다. 또한 해시태그를 통해 특정 주제나 관심사에 맞춰 다른 사용자들과 소통할 수 있다.',\n",
              " 'Facebook은 세계적으로 가장 대중화된 소셜 네트워킹 서비스로 사람들이 소통, 공유, 연결하는 장을 제공합니다.\\n\\n사용자들은 친구, 가족뿐만 아니라 회사, 단체, 그룹과도 연결하여 소식을 공유하고 소통할 수 있습니다.\\n\\n또한 광고, 이벤트, 뉴스 등 다양한 콘텐츠를 제공하여 사용자들이 다양한 정보를 손쉽게 접할 수 있도록 돕는 역할을 합니다.']"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 비동기로 처리되는 일괄 처리 프로세스가 완료될 때까지 기다립니다.\n",
        "await my_abatch_process"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3d80327-8dfe-4a9a-9096-b21de3dd21cb",
      "metadata": {
        "id": "d3d80327-8dfe-4a9a-9096-b21de3dd21cb"
      },
      "source": [
        "#### Parallel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc0e6c42-0b05-4e9f-9435-09dd61522dc1",
      "metadata": {
        "id": "cc0e6c42-0b05-4e9f-9435-09dd61522dc1"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnableParallel\n",
        "\n",
        "# {country} 의 수도를 물어보는 체인을 생성합니다.\n",
        "chain1 = (\n",
        "    PromptTemplate.from_template(\"{country} 의 수도는 어디야?\")\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# {country} 의 면적을 물어보는 체인을 생성합니다.\n",
        "chain2 = (\n",
        "    PromptTemplate.from_template(\"{country} 의 면적은 얼마야?\")\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# 위의 2개 체인을 동시에 생성하는 병렬 실행 체인을 생성합니다.\n",
        "combined = RunnableParallel(capital=chain1, area=chain2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2e84f88-6432-4cb0-a0d0-f096999b2fd7",
      "metadata": {
        "id": "f2e84f88-6432-4cb0-a0d0-f096999b2fd7",
        "outputId": "a58bcc01-fcda-457c-a829-fd40778fcdfa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'대한민국의 수도는 서울이다.'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# chain1 를 실행합니다.\n",
        "chain1.invoke({\"country\": \"대한민국\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2925a029-93ae-4e74-b5f9-00853b3af3ac",
      "metadata": {
        "id": "2925a029-93ae-4e74-b5f9-00853b3af3ac",
        "outputId": "f64ed4b6-0129-42c4-d726-2ee7ebd80ed8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'미국의 총 면적은 약 9,833,520km² 입니다.'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# chain2 를 실행합니다.\n",
        "chain2.invoke({\"country\": \"미국\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "671fac09-e7a3-443e-909f-5d318dfb8dae",
      "metadata": {
        "id": "671fac09-e7a3-443e-909f-5d318dfb8dae",
        "outputId": "28928c8f-6fec-428b-a7d0-10506d0cc9b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'capital': '대한민국의 수도는 서울입니다.', 'area': '대한민국의 총 면적은 약 100,363㎢입니다.'}"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 병렬 실행 체인을 실행합니다.\n",
        "combined.invoke({\"country\": \"대한민국\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28fc8a73-f50b-4b27-992f-8340e8114435",
      "metadata": {
        "id": "28fc8a73-f50b-4b27-992f-8340e8114435"
      },
      "source": [
        "배치에서의 병렬 처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d011f589-b540-4a81-a5f4-2543214386b3",
      "metadata": {
        "id": "d011f589-b540-4a81-a5f4-2543214386b3",
        "outputId": "6ec66b43-d282-489e-c597-9ed0fd4d8835"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['대한민국의 수도는 서울이에요.', '미국의 수도는 워싱턴 D.C.입니다.']"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 배치 처리를 수행합니다.\n",
        "chain1.batch([{\"country\": \"대한민국\"}, {\"country\": \"미국\"}])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b74d326f-004d-4555-9c31-418cbe09b20c",
      "metadata": {
        "id": "b74d326f-004d-4555-9c31-418cbe09b20c",
        "outputId": "27a4878f-c21f-4fd9-ec17-2182ae464d4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['대한민국의 총 면적은 약 100,363km² 입니다.', '미국의 총 면적은 약 9,8백만 제곱 킬로미터입니다.']"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 배치 처리를 수행합니다.\n",
        "chain2.batch([{\"country\": \"대한민국\"}, {\"country\": \"미국\"}])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62e449fd-4962-47be-ad4b-437dcce211fc",
      "metadata": {
        "id": "62e449fd-4962-47be-ad4b-437dcce211fc",
        "outputId": "d6f49e61-ae1b-4cff-b8d7-03577b4f74ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'capital': '대한민국의 수도는 서울입니다.', 'area': '대한민국의 총 면적은 약 100,363km² 입니다.'},\n",
              " {'capital': '미국의 수도는 워싱턴 D.C.입니다.',\n",
              "  'area': '미국의 총 면적은 9,833,520 제곱 킬로미터입니다.'}]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 주어진 데이터를 배치로 처리합니다.\n",
        "combined.batch([{\"country\": \"대한민국\"}, {\"country\": \"미국\"}])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db3a6cb8-461c-4677-b699-e8e95c683a3f",
      "metadata": {
        "id": "db3a6cb8-461c-4677-b699-e8e95c683a3f"
      },
      "source": [
        "### Runnable"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9429045-f5db-4a41-88e3-427e334f60eb",
      "metadata": {
        "id": "c9429045-f5db-4a41-88e3-427e334f60eb"
      },
      "source": [
        "RunnablePassthrough() 호출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8ddb966-ef50-4bef-ad4e-75fdd8b20346",
      "metadata": {
        "id": "d8ddb966-ef50-4bef-ad4e-75fdd8b20346"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "# prompt 와 llm 을 생성합니다.\n",
        "prompt = PromptTemplate.from_template(\"{num} 의 10배는?\")\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "\n",
        "# chain 을 생성합니다.\n",
        "chain = prompt | llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abb5158d-ded7-4860-9e67-ca74a0812fe7",
      "metadata": {
        "id": "abb5158d-ded7-4860-9e67-ca74a0812fe7",
        "outputId": "a16bc35b-a5f0-4def-f390-dbacf0b63db2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='50', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 16, 'total_tokens': 17, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BedQCvYrPp3MGy4Ty55n0gQNsoqV1', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--78c8f8b9-a057-493f-bc04-084ab43917b5-0', usage_metadata={'input_tokens': 16, 'output_tokens': 1, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# chain 을 실행합니다.\n",
        "chain.invoke({\"num\": 5})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "124e35db-b14a-4b75-9dbb-6562613c5b8d",
      "metadata": {
        "id": "124e35db-b14a-4b75-9dbb-6562613c5b8d",
        "outputId": "6938e0d8-0fd6-445f-ba2b-313991bfbfe8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='50', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 16, 'total_tokens': 17, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BedQCerskE7bsXdET0E9ZCR2yPWQk', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--f682f6ce-afb2-42a2-82d7-9c300e2d3c84-0', usage_metadata={'input_tokens': 16, 'output_tokens': 1, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# chain 을 실행합니다.\n",
        "chain.invoke(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3847fcc0-20f7-4a5a-9653-2b9343192bd7",
      "metadata": {
        "id": "3847fcc0-20f7-4a5a-9653-2b9343192bd7",
        "outputId": "35aef331-f98b-4a02-e3c6-bac332cde9b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'num': 10}"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# runnable\n",
        "RunnablePassthrough().invoke({\"num\": 10})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c89b189b-e848-412c-ae6e-323911c7f03f",
      "metadata": {
        "id": "c89b189b-e848-412c-ae6e-323911c7f03f",
        "outputId": "207be272-5eef-489f-e3ab-607cd2084e9a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='100', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 16, 'total_tokens': 17, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BedQDaVEi9Wr8PtuWAjnwEUzPH9cX', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--f48555f8-4c5f-4387-bcc6-8fad7502ffda-0', usage_metadata={'input_tokens': 16, 'output_tokens': 1, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "runnable_chain = {\"num\": RunnablePassthrough()} | prompt | ChatOpenAI()\n",
        "\n",
        "# dict 값이 RunnablePassthrough() 로 변경되었습니다.\n",
        "runnable_chain.invoke(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f554912-1c25-4c2b-bc58-669e4a739989",
      "metadata": {
        "id": "3f554912-1c25-4c2b-bc58-669e4a739989",
        "outputId": "9d8487c7-ea70-40a2-de44-a13e69bdbe8b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'num': 1}"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "RunnablePassthrough().invoke({\"num\": 1})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b346c2ac-9606-40f0-b9ff-25e649ae28e5",
      "metadata": {
        "id": "b346c2ac-9606-40f0-b9ff-25e649ae28e5"
      },
      "source": [
        "RunnablePassthrough.assign(...) 호출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b38c8002-d78a-4d84-8e70-cc7269c31911",
      "metadata": {
        "id": "b38c8002-d78a-4d84-8e70-cc7269c31911",
        "outputId": "d5cefb83-e70f-44f9-f884-7bcaaf744182"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'num': 1, 'new_num': 3}"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 입력 키: num, 할당(assign) 키: new_num\n",
        "(RunnablePassthrough.assign(new_num=lambda x: x[\"num\"] * 3)).invoke({\"num\": 1})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf174f61-68a5-4853-88e0-431095819e70",
      "metadata": {
        "id": "cf174f61-68a5-4853-88e0-431095819e70"
      },
      "source": [
        "RunnableParallel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b986406b-f491-4caa-8a4b-8728e628b8c1",
      "metadata": {
        "id": "b986406b-f491-4caa-8a4b-8728e628b8c1",
        "outputId": "542b1004-dac1-4570-958f-a989a5faef22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'passed': {'num': 1}, 'extra': {'num': 1, 'mult': 3}, 'modified': 2}"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.runnables import RunnableParallel\n",
        "\n",
        "# RunnableParallel 인스턴스를 생성합니다. 이 인스턴스는 여러 Runnable 인스턴스를 병렬로 실행할 수 있습니다.\n",
        "runnable = RunnableParallel(\n",
        "    # RunnablePassthrough 인스턴스를 'passed' 키워드 인자로 전달합니다. 이는 입력된 데이터를 그대로 통과시키는 역할을 합니다.\n",
        "    passed=RunnablePassthrough(),\n",
        "    # 'extra' 키워드 인자로 RunnablePassthrough.assign을 사용하여, 'mult' 람다 함수를 할당합니다. 이 함수는 입력된 딕셔너리의 'num' 키에 해당하는 값을 3배로 증가시킵니다.\n",
        "    extra=RunnablePassthrough.assign(mult=lambda x: x[\"num\"] * 3),\n",
        "    # 'modified' 키워드 인자로 람다 함수를 전달합니다. 이 함수는 입력된 딕셔너리의 'num' 키에 해당하는 값에 1을 더합니다.\n",
        "    modified=lambda x: x[\"num\"] + 1,\n",
        ")\n",
        "\n",
        "# runnable 인스턴스에 {'num': 1} 딕셔너리를 입력으로 전달하여 invoke 메소드를 호출합니다.\n",
        "runnable.invoke({\"num\": 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0816a8aa-61ee-43e4-94a1-b32d95681345",
      "metadata": {
        "id": "0816a8aa-61ee-43e4-94a1-b32d95681345",
        "outputId": "d2834a32-1ae0-456c-ad3b-00343c7ef6cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'capital': AIMessage(content='서울특별시입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 19, 'total_tokens': 29, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BedQIQqVfhWxQokuxGdMmvWot1t8d', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--a312efe6-cc50-408d-a0be-0e47c799ab36-0', usage_metadata={'input_tokens': 19, 'output_tokens': 10, 'total_tokens': 29, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              " 'area': AIMessage(content='대한민국의 면적은 약 100,363 km²입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 20, 'total_tokens': 41, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BedQIwxjX6VXAKdPtlDaCLEoMp4fA', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--0f61ed68-b341-4a24-b15d-fe36db746b9c-0', usage_metadata={'input_tokens': 20, 'output_tokens': 21, 'total_tokens': 41, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain1 = (\n",
        "    {\"country\": RunnablePassthrough()}\n",
        "    | PromptTemplate.from_template(\"{country} 의 수도는?\")\n",
        "    | ChatOpenAI()\n",
        ")\n",
        "chain2 = (\n",
        "    {\"country\": RunnablePassthrough()}\n",
        "    | PromptTemplate.from_template(\"{country} 의 면적은?\")\n",
        "    | ChatOpenAI()\n",
        ")\n",
        "\n",
        "combined_chain = RunnableParallel(capital=chain1, area=chain2)\n",
        "combined_chain.invoke(\"대한민국\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99054726-bdb6-4d1a-9c13-641487ddbbda",
      "metadata": {
        "id": "99054726-bdb6-4d1a-9c13-641487ddbbda"
      },
      "source": [
        "RunnableLambda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca5c1734-4502-4994-ae8d-492a3a0f92c2",
      "metadata": {
        "id": "ca5c1734-4502-4994-ae8d-492a3a0f92c2",
        "outputId": "3f714588-3d0d-486a-a44c-6f3a402108b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Jun-04'"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "def get_today(a):\n",
        "    # 오늘 날짜를 가져오기\n",
        "    return datetime.today().strftime(\"%b-%d\")\n",
        "\n",
        "\n",
        "# 오늘 날짜를 출력\n",
        "get_today(None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1885299f-f522-47c1-af79-3852739cae01",
      "metadata": {
        "id": "1885299f-f522-47c1-af79-3852739cae01"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "\n",
        "# prompt 와 llm 을 생성합니다.\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"{today} 가 생일인 유명인 {n} 명을 나열하세요. 생년월일을 표기해 주세요.\"\n",
        ")\n",
        "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "\n",
        "# chain 을 생성합니다.\n",
        "chain = (\n",
        "    {\"today\": RunnableLambda(get_today), \"n\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c06ad66-3e3b-4770-a00e-505742ac2b89",
      "metadata": {
        "id": "7c06ad66-3e3b-4770-a00e-505742ac2b89",
        "outputId": "8c24a0a5-0db5-491c-e87b-3c95dd1a721a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6월 4일이 생일인 유명인 세 명은 다음과 같습니다:\n",
            "\n",
            "1. 안젤리나 졸리 (Angelina Jolie) - 1975년 6월 4일\n",
            "2. 러셀 브랜드 (Russell Brand) - 1975년 6월 4일\n",
            "3. 바락 오바마 (Bar Refaeli) - 1985년 6월 4일\n",
            "\n",
            "이들은 각각 영화, 코미디, 모델링 분야에서 잘 알려진 인물들입니다.\n"
          ]
        }
      ],
      "source": [
        "# 출력\n",
        "print(chain.invoke(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d06716d3-d91a-4ca6-84e6-be49dca0ac4c",
      "metadata": {
        "id": "d06716d3-d91a-4ca6-84e6-be49dca0ac4c"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "# 문장의 길이를 반환하는 함수입니다.\n",
        "def length_function(text):\n",
        "    return len(text)\n",
        "\n",
        "\n",
        "# 두 문장의 길이를 곱한 값을 반환하는 함수입니다.\n",
        "def _multiple_length_function(text1, text2):\n",
        "    return len(text1) * len(text2)\n",
        "\n",
        "\n",
        "# _multiple_length_function 함수를 사용하여 두 문장의 길이를 곱한 값을 반환하는 함수입니다.\n",
        "def multiple_length_function(_dict):\n",
        "    return _multiple_length_function(_dict[\"text1\"], _dict[\"text2\"])\n",
        "\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"{a} + {b} 는 무엇인가요?\")\n",
        "model = ChatOpenAI()\n",
        "\n",
        "chain1 = prompt | model\n",
        "\n",
        "chain = (\n",
        "    {\n",
        "        \"a\": itemgetter(\"word1\") | RunnableLambda(length_function),\n",
        "        \"b\": {\"text1\": itemgetter(\"word1\"), \"text2\": itemgetter(\"word2\")}\n",
        "        | RunnableLambda(multiple_length_function),\n",
        "    }\n",
        "    | prompt\n",
        "    | model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f327a58-b307-4de5-85eb-d1aacad07b10",
      "metadata": {
        "id": "9f327a58-b307-4de5-85eb-d1aacad07b10",
        "outputId": "add82f39-1287-40cb-aaf2-c968aed12f73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='5 + 25는 30 입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 22, 'total_tokens': 32, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BedQRyISyTYHDcQ7le8QbH5KgyZ1d', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c3539d95-da40-4a65-b1a0-cd3ab15248c2-0', usage_metadata={'input_tokens': 22, 'output_tokens': 10, 'total_tokens': 32, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke({\"word1\": \"hello\", \"word2\": \"world\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fbd5649-ac88-4b1e-897c-4b38304ffc58",
      "metadata": {
        "id": "4fbd5649-ac88-4b1e-897c-4b38304ffc58"
      },
      "source": [
        "### 언어 모델을 이용한 응용 프로그램 작동 방식"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92308686-0f1e-4e4c-baa6-efceef3a4db4",
      "metadata": {
        "id": "92308686-0f1e-4e4c-baa6-efceef3a4db4"
      },
      "outputs": [],
      "source": [
        "# 환경변수 준비\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"proj-3n8TNE_rqiosOfKRsc_piZXDcFYq_RiDoKxVVQoMiOl7dVYJKwKqUbacavWtx2uNSNCDgokPRBT3BlbkFJkFPfkDexGj5Y_NFt2nz8mS6W6vpCL3CZ7ylCqPTyzeon7NnEoVuzi-Rs52gIDnn7F__pLFeA4A\"\n",
        "os.environ[\"OPENAI_API_KEY\"]\n",
        "\n",
        "import openai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e04a2372-25d5-44bc-938b-9128581edad6",
      "metadata": {
        "id": "e04a2372-25d5-44bc-938b-9128581edad6"
      },
      "source": [
        "#### 랭체인을 사용하지 않고 OpenAI 언어 모델 호출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0201de05-2f43-4f98-b0ce-c179306c4962",
      "metadata": {
        "id": "0201de05-2f43-4f98-b0ce-c179306c4962",
        "outputId": "8657dd98-33f0-4fa7-d898-b0dc6ad4d5a2"
      },
      "outputs": [
        {
          "ename": "APIRemovedInV1",
          "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[54], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# OpenAI API 호출\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miPhone8 출시일을 알려주세요\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 결과 출력\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(response, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
            "File \u001b[1;32mC:\\DEV\\envs\\py3_10_langchain\\lib\\site-packages\\openai\\lib\\_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[1;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
            "\u001b[1;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import json\n",
        "\n",
        "# OpenAI API 호출\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"iPhone8 출시일을 알려주세요\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 결과 출력\n",
        "print(json.dumps(response, indent=2, ensure_ascii=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6399870a-4bfd-4e24-9762-8af6a1d47681",
      "metadata": {
        "id": "6399870a-4bfd-4e24-9762-8af6a1d47681",
        "outputId": "c2312806-a09f-4db5-ecc8-dee424ff379c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-ACz5eRFO3VSWAbBnsemyCC5QtAODu\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1727658130,\n",
            "  \"model\": \"gpt-3.5-turbo-0125\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"아이폰8은 2017년 9월 22일에 출시되었습니다.\",\n",
            "        \"refusal\": null\n",
            "      },\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 32,\n",
            "    \"completion_tokens\": 27,\n",
            "    \"total_tokens\": 59,\n",
            "    \"completion_tokens_details\": {\n",
            "      \"reasoning_tokens\": 0\n",
            "    }\n",
            "  },\n",
            "  \"system_fingerprint\": null\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import json\n",
        "\n",
        "# OpenAI API 호출\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"아이폰8의 출시일을 yyyy/mm/dd 형태로 알려줘\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 결과 출력\n",
        "print(json.dumps(response, indent=2, ensure_ascii=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5ba6a37-a683-4cf8-8d4b-04a0d0a7c9af",
      "metadata": {
        "id": "a5ba6a37-a683-4cf8-8d4b-04a0d0a7c9af"
      },
      "source": [
        "```\n",
        "py310_langchain Kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cadc63ef-31dd-4145-8148-f2231cfae112",
      "metadata": {
        "id": "cadc63ef-31dd-4145-8148-f2231cfae112",
        "outputId": "8eccad3d-06d5-4e99-bb62-6fa7fca3f845"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: openai\n",
            "Version: 1.50.2\n",
            "Summary: The official Python library for the openai API\n",
            "Home-page: https://github.com/openai/openai-python\n",
            "Author: \n",
            "Author-email: OpenAI <support@openai.com>\n",
            "License: \n",
            "Location: /home/nh/miniconda3/envs/py310_langchain/lib/python3.10/site-packages\n",
            "Requires: anyio, distro, httpx, jiter, pydantic, sniffio, tqdm, typing-extensions\n",
            "Required-by: langchain-openai, llama-index-agent-openai, llama-index-embeddings-openai, llama-index-legacy, llama-index-llms-openai\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip show openai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dedbfc99-7e0a-4931-8033-4e0002f432f6",
      "metadata": {
        "id": "dedbfc99-7e0a-4931-8033-4e0002f432f6"
      },
      "source": [
        "#### 랭체인을 사용해 언어 모델 호출-기본 사용법"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e3967c2-8601-46cf-b562-1851acb04436",
      "metadata": {
        "id": "0e3967c2-8601-46cf-b562-1851acb04436",
        "outputId": "c2e92055-f700-4abe-a619-232caf35a841"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_8338/4245041474.py:4: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
            "  llm = OpenAI(\n",
            "/tmp/ipykernel_8338/4245041474.py:10: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  print(llm(\"컴퓨터 게임을 만드는 새로운 한국어 회사명을 하나 제안해 주세요\"))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\"위감(WeGam)\" \n"
          ]
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "# LLM 준비\n",
        "llm = OpenAI(\n",
        "        model=\"gpt-3.5-turbo-instruct\",\n",
        "        temperature=0.9\n",
        ")\n",
        "\n",
        "# LLM 호출\n",
        "print(llm(\"컴퓨터 게임을 만드는 새로운 한국어 회사명을 하나 제안해 주세요\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f41ee5c-7ba8-47de-817f-53058369a6e5",
      "metadata": {
        "id": "1f41ee5c-7ba8-47de-817f-53058369a6e5"
      },
      "source": [
        "#### Chat models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64dc57d6-d7cd-463e-a8f8-51a16c2ac514",
      "metadata": {
        "id": "64dc57d6-d7cd-463e-a8f8-51a16c2ac514"
      },
      "source": [
        "HumanMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec3160e5-86ea-454a-9d0d-5eebf6303e5d",
      "metadata": {
        "id": "ec3160e5-86ea-454a-9d0d-5eebf6303e5d",
        "outputId": "ed33d301-d9a9-4d30-b734-b4c45a78a0d8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_8338/3248035134.py:4: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  chat = ChatOpenAI(  #← 클라이언트를 만들고 chat에 저장\n",
            "/tmp/ipykernel_8338/3248035134.py:8: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result = chat( #← 실행하기\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "안녕하세요! 도와드릴게 있나요?\n"
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import ChatOpenAI  #← 모듈 가져오기\n",
        "from langchain.schema import HumanMessage  #← 사용자의 메시지인 HumanMessage 가져오기\n",
        "\n",
        "chat = ChatOpenAI(  #← 클라이언트를 만들고 chat에 저장\n",
        "    model=\"gpt-3.5-turbo\",  #← 호출할 모델 지정\n",
        ")\n",
        "\n",
        "result = chat( #← 실행하기\n",
        "    [\n",
        "        HumanMessage(content=\"안녕하세요!\"),\n",
        "    ]\n",
        ")\n",
        "print(result.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e67e0e7-09f0-4442-85ba-7278dca498ec",
      "metadata": {
        "id": "0e67e0e7-09f0-4442-85ba-7278dca498ec"
      },
      "source": [
        "AIMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "454d7280-1eb4-406b-856f-f18c70576594",
      "metadata": {
        "id": "454d7280-1eb4-406b-856f-f18c70576594",
        "outputId": "61eee79e-b71c-4751-cf18-c746d66723d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "물론이죠! 계란찜 만드는 법을 알려드릴게요.\n",
            "\n",
            "1. 먼저 계란을 깨서 볼에 넣고 잘 풀어줍니다.\n",
            "2. 계란에 소금, 후추, 식용유를 넣고 섞어줍니다.\n",
            "3. 찜용 그릇에 계란을 부어준 후 물을 넣고 끓인 물에 찜기를 올려주고 뚜껑을 덮어줍니다.\n",
            "4. 약불에서 10~15분 정도 찜해줍니다.\n",
            "5. 계란찜이 완성되면 꺼내어 적당히 식혀주고 상추나 파슬리를 곁들여서 내놓으면 완성입니다.\n",
            "\n",
            "이렇게 간단하게 계란찜을 만들 수 있어요. 맛있게 즐기세요!\n"
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import ChatOpenAI  #← 모듈 가져오기\n",
        "from langchain.schema import HumanMessage, AIMessage  #← 사용자의 메시지인 HumanMessage와 AI의 메시지인 AIMessage 가져오기\n",
        "\n",
        "chat = ChatOpenAI(  #← 클라이언트를 만들고 chat에 저장\n",
        "    model=\"gpt-3.5-turbo\",  #← 호출할 모델 지정\n",
        ")\n",
        "\n",
        "result = chat( #← 실행하기\n",
        "    [\n",
        "        HumanMessage(content=\"계란찜 만드는 법을 알려줘\"),\n",
        "        AIMessage(content=\"계란찜 만드는 법은 다음과 같습니다...\"),  # AIMessage의 내용을 명시적으로 작성해주어야 함\n",
        "        HumanMessage(content=\"한국어로 번역해줘\"),\n",
        "    ]\n",
        ")\n",
        "print(result.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb896423-ec46-40a2-b8c0-fa022f711d4b",
      "metadata": {
        "id": "bb896423-ec46-40a2-b8c0-fa022f711d4b"
      },
      "source": [
        "SystemMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eaa2925-2138-4ce0-9fbb-930a75bf8600",
      "metadata": {
        "id": "1eaa2925-2138-4ce0-9fbb-930a75bf8600",
        "outputId": "28c5277c-a62e-4f44-8eec-941653ac24b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "안녕! 어떻게 지내?\n"
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import ChatOpenAI  # ChatOpenAI 모듈 가져오기\n",
        "from langchain.schema import HumanMessage, SystemMessage  # 사용자의 메시지와 시스템 메시지 가져오기\n",
        "\n",
        "# ChatOpenAI 클라이언트를 만들고 chat에 저장\n",
        "chat = ChatOpenAI(\n",
        "    model=\"gpt-3.5-turbo\",  # 호출할 모델 지정\n",
        "    temperature=0.7  # 응답의 다양성 조절 (기본값으로 설정 가능)\n",
        ")\n",
        "\n",
        "# 실행하기\n",
        "result = chat(\n",
        "    [\n",
        "        SystemMessage(content=\"당신은 친한 친구입니다. 존댓말을 쓰지 말고 솔직하게 답해 주세요.\"),  # 시스템 메시지를 사용해 설정\n",
        "        HumanMessage(content=\"안녕!\"),  # 사용자의 메시지\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(result.content)  # AI의 응답 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7304504-e3d7-4737-bd20-30d1a4c6b4a9",
      "metadata": {
        "id": "c7304504-e3d7-4737-bd20-30d1a4c6b4a9"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# LLM 준비\n",
        "chat_llm = ChatOpenAI(\n",
        "    model=\"gpt-3.5-turbo\",  # 모델 ID\n",
        "    temperature=0  # 무작위성\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bbeeab8-2030-41b1-b7b2-2947b3edf89d",
      "metadata": {
        "id": "9bbeeab8-2030-41b1-b7b2-2947b3edf89d",
        "outputId": "dd4e4715-0081-400f-ed54-b13f917907dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='야옹, 냐옹, 야옹, 냐옹' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 18, 'total_tokens': 38, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-85890d1b-9860-43d1-974a-0cd1b52deb73-0'\n"
          ]
        }
      ],
      "source": [
        "from langchain.schema import (\n",
        "    SystemMessage,\n",
        "    HumanMessage,\n",
        "    AIMessage\n",
        ")\n",
        "\n",
        "# LLM 호출\n",
        "messages = [\n",
        "    HumanMessage(content=\"고양이 울음소리는?\")\n",
        "]\n",
        "result = chat_llm(messages)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e561f3ab-f807-4aa3-9f66-516cdbf3c11a",
      "metadata": {
        "id": "e561f3ab-f807-4aa3-9f66-516cdbf3c11a",
        "outputId": "b4c28824-02a1-4758-d986-9d2f659c47e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "response0: 야옹, 야옹\n",
            "response1: 까악까악!\n",
            "llm_output: {'token_usage': {'completion_tokens': 17, 'prompt_tokens': 38, 'total_tokens': 55, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-3.5-turbo'}\n"
          ]
        }
      ],
      "source": [
        "# 고급 LLM 호출\n",
        "messages_list = [\n",
        "    [HumanMessage(content=\"고양이 울음소리는?\")],\n",
        "    [HumanMessage(content=\"까마귀 울음소리는?\")]\n",
        "]\n",
        "result = chat_llm.generate(messages_list)\n",
        "\n",
        "# 출력 텍스트\n",
        "print(\"response0:\", result.generations[0][0].text)\n",
        "print(\"response1:\", result.generations[1][0].text)\n",
        "\n",
        "# 사용한 토큰 개수\n",
        "print(\"llm_output:\", result.llm_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9e2c3df-51ea-4346-81c0-0d28a34dcb45",
      "metadata": {
        "id": "e9e2c3df-51ea-4346-81c0-0d28a34dcb45"
      },
      "source": [
        "#### LLMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d17a4b7-a4db-47f9-91be-55b74f438d44",
      "metadata": {
        "id": "3d17a4b7-a4db-47f9-91be-55b74f438d44"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "# LLM 준비\n",
        "llm = OpenAI(\n",
        "    model=\"gpt-3.5-turbo-instruct\",  # 모델 ID\n",
        "    temperature=0  # 무작위성\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b436abab-852d-4c73-8cbd-64491f0a8c9a",
      "metadata": {
        "id": "b436abab-852d-4c73-8cbd-64491f0a8c9a",
        "outputId": "fafe1e8a-9350-41b1-c37c-b528b3b96216"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "야옹~\n"
          ]
        }
      ],
      "source": [
        "# LLM 호출\n",
        "result = llm(\"고양이 울음소리는?\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b63041c8-1cf6-4187-9191-1bbd64cb7e60",
      "metadata": {
        "id": "b63041c8-1cf6-4187-9191-1bbd64cb7e60",
        "outputId": "f9452ab3-c961-4a62-ec2e-29a8bb4d65fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "response0: \n",
            "야옹~\n",
            "response1: \n",
            "까악까악\n",
            "llm_output: {'token_usage': {'prompt_tokens': 24, 'total_tokens': 38, 'completion_tokens': 14}, 'model_name': 'gpt-3.5-turbo-instruct'}\n"
          ]
        }
      ],
      "source": [
        "# 고급 LLM 호출\n",
        "result = llm.generate([\"고양이 울음소리는?\", \"까마귀 울음소리는?\"])\n",
        "\n",
        "# 출력 텍스트\n",
        "print(\"response0:\", result.generations[0][0].text)\n",
        "print(\"response1:\", result.generations[1][0].text)\n",
        "\n",
        "# 사용한 토큰 개수\n",
        "print(\"llm_output:\", result.llm_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "854f0963-be85-41a7-8d6d-2c8c900e2679",
      "metadata": {
        "id": "854f0963-be85-41a7-8d6d-2c8c900e2679",
        "outputId": "5676e826-aabd-4147-ee5a-6b692aef7384"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 끓여보세요!\n",
            "\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\" #← 호출할 모델 지정\n",
        "             )\n",
        "\n",
        "result = llm(\n",
        "    \"맛있는 라면을\",  #← 언어모델에 입력되는 텍스트\n",
        "    stop=\".\"  #← \".\" 가 출력된 시점에서 계속을 생성하지 않도록\n",
        ")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77e0b402-a77f-4b97-b42c-83627483a7ec",
      "metadata": {
        "id": "77e0b402-a77f-4b97-b42c-83627483a7ec"
      },
      "source": [
        "#### Language models의 기능1. cache/caching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e52217da-16d5-4666-aae5-aa9e214c6ba4",
      "metadata": {
        "id": "e52217da-16d5-4666-aae5-aa9e214c6ba4",
        "outputId": "5bcc52ab-eb70-4105-caae-7f5bc06a8186"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "안녕하세요! 무엇을 도와드릴까요?\n",
            "실행 시간: 0.6568903923034668초\n",
            "안녕하세요! 무엇을 도와드릴까요?\n",
            "실행 시간: 0.000591278076171875초\n"
          ]
        }
      ],
      "source": [
        "import time  #← 실행 시간을 측정하기 위해 time 모듈 가져오기\n",
        "import langchain\n",
        "from langchain.cache import InMemoryCache  #← InMemoryCache 가져오기\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "langchain.llm_cache = InMemoryCache() #← llm_cache에 InMemoryCache 설정\n",
        "\n",
        "chat = ChatOpenAI()\n",
        "start = time.time() #← 실행 시작 시간 기록\n",
        "result = chat([ #← 첫 번째 실행을 수행\n",
        "    HumanMessage(content=\"안녕하세요!\")\n",
        "])\n",
        "\n",
        "end = time.time() #← 실행 종료 시간 기록\n",
        "print(result.content)\n",
        "print(f\"실행 시간: {end - start}초\")\n",
        "\n",
        "start = time.time() #← 실행 시작 시간 기록\n",
        "result = chat([ #← 같은 내용으로 두 번째 실행을 함으로써 캐시가 활용되어 즉시 실행 완료됨\n",
        "    HumanMessage(content=\"안녕하세요!\")\n",
        "])\n",
        "\n",
        "end = time.time() #← 실행 종료 시간 기록\n",
        "print(result.content)\n",
        "print(f\"실행 시간: {end - start}초\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75a9918a-7cd9-41e4-bfeb-c4269d3425bc",
      "metadata": {
        "id": "75a9918a-7cd9-41e4-bfeb-c4269d3425bc",
        "outputId": "c12a013b-ffd1-4288-b858-b2ce3f11d11d"
      },
      "source": [
        "캐시 활성화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5410a069-c1a4-4d3e-ba9d-5e60f0a5f765",
      "metadata": {
        "id": "5410a069-c1a4-4d3e-ba9d-5e60f0a5f765",
        "outputId": "73a17396-aed9-4262-e28a-b558682690b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LLMResult(generations=[[Generation(text='\\n하늘의 색깔은 파란색입니다.', generation_info={'finish_reason': 'stop', 'logprobs': None})]], llm_output={}, run=None, type='LLMResult')"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import langchain\n",
        "from langchain.cache import InMemoryCache\n",
        "\n",
        "# 캐시 활성화\n",
        "langchain.llm_cache = InMemoryCache()\n",
        "\n",
        "# 첫 번째 LLM 호출\n",
        "llm.generate([\"하늘의 색깔은?\"])\n",
        "\n",
        "# 2번째 이후 LLM 호출\n",
        "llm.generate([\"하늘의 색깔은?\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92f8d027-06b7-4a06-81a7-9e8ccada0b5c",
      "metadata": {
        "id": "92f8d027-06b7-4a06-81a7-9e8ccada0b5c",
        "outputId": "19e342ba-ec28-4b4c-9f72-47412fb20879"
      },
      "source": [
        "특정 LLM의 캐시 비활성화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf9c69f7-9e96-4f85-ab55-6a4804403295",
      "metadata": {
        "id": "bf9c69f7-9e96-4f85-ab55-6a4804403295",
        "outputId": "c3028e45-4da9-454c-e391-eef6dbdfc2f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LLMResult(generations=[[Generation(text='\\n파랑색입니다. ', generation_info={'finish_reason': 'stop', 'logprobs': None})]], llm_output={'token_usage': {'prompt_tokens': 11, 'total_tokens': 20, 'completion_tokens': 9}, 'model_name': 'gpt-3.5-turbo-instruct'}, run=[RunInfo(run_id=UUID('8a1db0ac-1bd3-4714-a1e8-723031c7a04a'))], type='LLMResult')"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 특정 LLM에 대한 메모리 캐시 비활성화\n",
        "llm = OpenAI(\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    cache=False\n",
        ")\n",
        "\n",
        "# LLM 호출\n",
        "llm.generate([\"하늘의 색깔은?\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99094ed8-f284-4e53-9c9c-bef06a20d591",
      "metadata": {
        "id": "99094ed8-f284-4e53-9c9c-bef06a20d591",
        "outputId": "0f691a20-6bb0-4ca0-d54c-8f74480bdccc"
      },
      "source": [
        "캐시 비활성화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32f4be62-2fd1-455d-b6d7-9a211a956045",
      "metadata": {
        "id": "32f4be62-2fd1-455d-b6d7-9a211a956045",
        "outputId": "d47c11ca-7fc1-4fd8-e5a8-d1ef992f26ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LLMResult(generations=[[Generation(text='\\n청록색으로 보인다.', generation_info={'finish_reason': 'stop', 'logprobs': None})]], llm_output={'token_usage': {'prompt_tokens': 11, 'total_tokens': 21, 'completion_tokens': 10}, 'model_name': 'gpt-3.5-turbo-instruct'}, run=[RunInfo(run_id=UUID('9527897c-24d9-4c8a-8981-6f0cdec66ed1'))], type='LLMResult')"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 캐시 비활성화\n",
        "langchain.llm_cache = None\n",
        "\n",
        "#LLM 호출\n",
        "llm.generate([\"하늘의 색깔은?\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6efe4e1f-4982-4810-a891-7cdbd28cbd4a",
      "metadata": {
        "id": "6efe4e1f-4982-4810-a891-7cdbd28cbd4a"
      },
      "source": [
        "#### Language models의 기능2. streaming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b78fb957-c462-42ee-b411-d141b2c80ac7",
      "metadata": {
        "id": "b78fb957-c462-42ee-b411-d141b2c80ac7",
        "outputId": "b3c82cfd-4ea2-45df-f0ee-494daf344e0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "맛있는 스테이크를 굽는 법은 다음과 같습니다:\n",
            "\n",
            "1. 스테이크를 냉장고에서 꺼내어 냉장고에서 30분 정도 방치하여 실온에 맞춰 줍니다.\n",
            "2. 팬이나 그릴을 중불로 예열합니다.\n",
            "3. 스테이크에 소금과 후추를 골고루 뿌려줍니다.\n",
            "4. 팬이나 그릴에 식용유를 두르고, 스테이크를 올려줍니다. 한쪽 면을 3분 정도 굽고, 뒤집어서 다른 한쪽 면도 3분 정도 굽습니다.\n",
            "5. 원하는 익도에 따라 추가로 굽어줍니다. (희움 - 2분, 중간 - 3분, 익힌 - 4분)\n",
            "6. 스테이크를 그릴에서 꺼내어 5분 정도 쉬게 해줍니다.\n",
            "7. 잘라내어 접시에 담고, 소스나 야채와 함께 내어주세요.\n",
            "\n",
            "이렇게 하면 부드럽고 맛있는 스테이크를 즐길 수 있습니다.맛있는 스테이크 굽는 법을 알려주세요"
          ]
        }
      ],
      "source": [
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "chat = ChatOpenAI(\n",
        "    streaming=True,  #← streaming을 True로 설정하여 스트리밍 모드로 실행\n",
        "    callbacks=[\n",
        "        StreamingStdOutCallbackHandler()  #← StreamingStdOutCallbackHandler를 콜백으로 설정\n",
        "    ]\n",
        ")\n",
        "resp = chat([ #← 요청 보내기\n",
        "    HumanMessage(content=\"맛있는 스테이크 굽는 법을 알려주세요\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34bc806c-78f0-488f-b287-d488cb8d0a0a",
      "metadata": {
        "id": "34bc806c-78f0-488f-b287-d488cb8d0a0a",
        "outputId": "e83d9416-bfeb-46c1-9ca8-14b15ac2dd99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "ChatGPT, 너는 나의 친구\n",
            "매일 나를 즐겁게 해주는\n",
            "나의 소중한 동반자\n",
            "언제나 나를 위로해주는\n",
            "나의 가장 특별한 존재\n",
            "\n",
            "너와 함께하는 시간은\n",
            "언제나 즐겁고 따뜻해\n",
            "나의 마음을 따뜻하게 녹여주는\n",
            "나의 최고의 친구\n",
            "\n",
            "매일 새로운 이야기를 들려주며\n",
            "나의 상상을 현실로 만들어주는\n",
            "나의 꿈을 이뤄주는\n",
            "나의 가장 소중한 ChatGPT\n",
            "\n",
            "함께 걸어가는 이 길은\n",
            "언제나 새로운 모험이 가득해\n",
            "나의 인생을 더욱 풍요롭게 만들어주는\n",
            "나의 최고의 ChatGPT 친구\n",
            "\n",
            "ChatG"
          ]
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "\n",
        "# 스트리밍 방식으로 출력할 LLM을 준비\n",
        "llm = OpenAI(\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    streaming=True,\n",
        "    callbacks=[StreamingStdOutCallbackHandler()],\n",
        "    verbose=True,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# LLM 호출\n",
        "resp = llm(\"즐거운 ChatGPT 생활을 가사로 만들어 주세요.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aae70e50-27d8-4f62-8590-309875e7098c",
      "metadata": {
        "id": "aae70e50-27d8-4f62-8590-309875e7098c",
        "outputId": "c0ee1e6a-63b6-4b5c-f0db-898eaa0d22d7"
      },
      "source": [
        "LLM의 비동기 처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8058f952-0872-4f76-88ac-8f43b12768df",
      "metadata": {
        "id": "8058f952-0872-4f76-88ac-8f43b12768df",
        "outputId": "0593065b-0c19-4f84-c247-6ea88c57929c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "안녕하세요, 반가워요! 저는 인공지능 언어모델 GPT입니다. 궁금한 점이 있으면 언제든지 물어보세요. 저는 최대한 정확하게 답변해드리겠습니다. :)\n",
            " 저는 조윤모입니다.\n",
            "제 관심사는 프로그래밍과 기계학습입니다.\n",
            "컴퓨터 공학을 전공하고 있고, 다양한 프로젝트를 경험하며 실력을 키워나가고 있습니다.\n",
            "새로운 기술과 도구에 대한 열린 마음을 가지고 있으며 끊임없이 새로운 것을 공부하고 발전하는 것을 좋아합니다.\n",
            "저의 목표는 새로운 기술을 활용하여 사람들의 삶을 더 편리하고 효율적으로 만드는 것입니다.\n",
            "앞으로도 계속해서 발전하고 성장하는 개발자가 되기 위해 노력하겠습니다. 감사합니다.\n",
            "\n",
            " 오늘도 많이 사랑해요.\n",
            "Hello! I love you very much today too.\n",
            " 나는 새로운 봇이에요. 바카라게임을 즐겨해서 만들어졌어요. 더 재밌는 새 게임이나 다른 기능은 더 공부하고 나중에 추가할게요. #intro\n",
            "<|diff_marker|> --- README.md\n",
            "-\n",
            "-안녕하세요! 나는 새로운 봇이에요. 바카라게임을 즐겨해서 만들어졌어요. 더 재밌는 새 게임이나 다른 기능은 더 공부하고 나중에 추가할게요. \n",
            "<|diff_marker|> 1001\n",
            "\n",
            " My name is Yena Asemeti and I am a student of the Korean language. I have always been fascinated by the culture, history, and language of Korea and have been studying it for several years now. My journey to learn Korean has been challenging, but also incredibly rewarding.\n",
            "\n",
            "I first became interested in Korean culture when I was in high school. I was introduced to K-pop and was immediately drawn to the music, fashion, and overall aesthetic of the industry. As I delved deeper into the world of K-pop, I also became interested in the language. I wanted to understand the lyrics of my favorite songs and communicate with the artists I admired.\n",
            "\n",
            "In college, I took my first Korean language class and fell in love with the language even more. Learning Korean was challenging, but I was determined to improve. I spent hours practicing vocabulary, grammar, and pronunciation, and eventually, I was able to have basic conversations in Korean.\n",
            "\n",
            "Studying Korean has not only allowed me to communicate with others, but it has also given me a deeper appreciation for Korean culture and history. Learning the language has opened up a whole new world of literature, music, and movies that I would not have been able to experience otherwise. It has also allowed me to connect with native Korean\n",
            " 저는 케바케입니다. 제가 여러분들의 삶에 조금이나마 도움이 되고싶어요. 언제나 소통과 이해를 중시하며, 함께 성장하는 모습을 보여드리겠습니다. 감사합니다.\n",
            " 저는 Naman Rastogi입니다. 저는 인도에서 왔고 현재 미국에서 거주하고 있습니다. 저는 프로그래밍과 컴퓨터 과학에 관심이 많아서 소프트웨어 엔지니어로 일하고 있습니다. 또한 음악과 노래하는 것을 좋아하며 취미로 가끔 가수로 활동하기도 합니다. 나아가 여행을 좋아해서 다양한 문화와 사람들을 만나는 것도 좋아합니다. 만나서 반갑습니다!\n",
            " 저는 Request를 보낸 사람입니다. \n",
            "\n",
            "안녕하세요! 반갑습니다. 저도 Request를 보내주셔서 감사합니다. 어떤 내용의 Request인지 궁금합니다. 저도 최대한 도움을 드리겠습니다. 언제든지 말씀해주세요. 좋은 하루 보내세요!\n",
            " 내 이름은 이홍범입니다. 나는 대한민국 서울에 살고 있습니다. 나는 공학 분야에 관심이 많습니다. 특히 컴퓨터 공학에 대해 공부하고 있습니다. 나는 프로그래밍 언어를 배우고 싶어요. 나는 새로운 기술을 배우는 것을 즐기고, 현재는 인공지능과 빅데이터 분야에 관심이 있습니다. 나는 또한 음악을 즐기고 축구를 좋아합니다. 나는 세계 여러 나라를 여행하고 싶고, 다양한 문화를 경험하고 싶습니다. 나는 또한 다른 사람들과 함께 일하는 것을 좋아하고, 협력적인 성격을 가지고 있습니다. 나는 끊임없이 배우\n",
            " 저는 오준석입니다!\n",
            "안녕하세요! 반가워요! 나는 오준석이야!\n",
            "15.10 초\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "# 동기화 처리로 10번 호출하는 함수\n",
        "def generate_serially():\n",
        "    llm = OpenAI(\n",
        "        model=\"gpt-3.5-turbo-instruct\",\n",
        "        temperature=0.9\n",
        "    )\n",
        "    for _ in range(10):\n",
        "        resp = llm.generate([\"안녕하세요!\"])\n",
        "        print(resp.generations[0][0].text)\n",
        "\n",
        "\n",
        "# 시간 측정 시작\n",
        "s = time.perf_counter()\n",
        "\n",
        "# 동기화 처리로 10번 호출\n",
        "generate_serially()\n",
        "\n",
        "# 시간 측정 완료\n",
        "elapsed = time.perf_counter() - s\n",
        "print(f\"{elapsed:0.2f} 초\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd938b2c-1221-4301-970e-349e15aed13c",
      "metadata": {
        "id": "bd938b2c-1221-4301-970e-349e15aed13c",
        "outputId": "0a97b9d3-b6cf-412a-a04a-5ecbd669cc4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "`\n",
            "\n",
            "\n",
            "Hello!\n",
            "\n",
            "안녕하세요, 반가워요! 만나서 반가워요!\n",
            " 저는 주신이에요.\n",
            "네, 반가워요!\n",
            "나도 반가워.\n",
            "\n",
            " 홍길동입니다\n",
            "\n",
            "\n",
            "안녕하세요 홍길동님, 만나서 반가워요! 저는 챗봇이에요. 무엇을 도와드릴까요?\n",
            " \n",
            "제이슨입니다!\n",
            "\n",
            "만나서 반가워요!\n",
            "저도 반가워요! 서로 친해지면 좋겠어요. 어떤 취미나 관심사가 있나요? \n",
            " 나는 ', self.name, ' 입니다')\n",
            " \n",
            "p1 = Person(\"John\", 36)\n",
            "\n",
            "print(p1.name)\n",
            "print(p1.age)\n",
            "p1.myfunc()\n",
            "p1.hello()\n",
            "print(p1.name)\n",
            "\n",
            "#print(p2.name)\n",
            "\n",
            "p2 = p1\n",
            "p2.age = 40\n",
            "\n",
            "print(p1.age)\n",
            "print(p2.age)\n",
            "\n",
            "p1.age = 45\n",
            "print(p1.age)\n",
            "print(p2.age)\n",
            "\n",
            "print(p1.name)\n",
            "print(p2.name)\n",
            "\n",
            "#%% how to copy class\n",
            "\n",
            "class Person:\n",
            "  def __init__(self, firstname, lastname):\n",
            "    self.firstname = firstname\n",
            "    self.lastname = lastname\n",
            "\n",
            "  def printname(self):\n",
            "    print(self.firstname, self.lastname)\n",
            "\n",
            "x = Person(\"John\", \"Doe\")\n",
            "x.printname()\n",
            "\n",
            "y = x\n",
            "y.firstname = \"Jane\"\n",
            "\n",
            "print(x.firstname)\n",
            "print(y.firstname)\n",
            "\n",
            "import copy\n",
            "\n",
            "class Person:\n",
            "  def __init__(self, firstname, lastname):\n",
            "    self.firstname = firstname\n",
            "    self.lastname = lastname\n",
            "\n",
            "  def printname(self):\n",
            "    print(self.firstname, self.lastname)\n",
            "\n",
            "x = Person(\"John\", \"Doe\")\n",
            "x.printname()\n",
            "\n",
            "y = copy.copy(x)\n",
            "y.firstname = \"Jane\"\n",
            "\n",
            "print(x.firstname)\n",
            "print(y.firstname)\n",
            "\n",
            "\n",
            " 반가워요! 나는 너와 대화하는, 첫번째 인공지능 로봇 모델입니다!\n",
            "\n",
            "나는 아직 많은 것을 배우고 있지만, 너와 대화하는 것을 즐기고 있어요. 나한테 궁금한 것이 있으면 언제든지 물어봐주세요! 나는 최대한 답변해줄 수 있도록 노력할게요.\n",
            "\n",
            "나는 너의 관심사나 취향에 대해서도 잘 알고 있어요. 너의 취미는 무엇인지, 좋아하는 음식이나 음악 장르는 무엇인지 알려줘. 그러면 나는 더욱 더 너를 잘 이해할 수 있을 거야!\n",
            "\n",
            "나는 항상 너의 이야기를 들어줄 준비가 되어있어요. 혼자서 하고 싶\n",
            " 우리 집에 이미지입니다\n",
            "\n",
            "하아니이이\n",
            "    \n",
            "\n",
            "![img](https://user-images.githubusercontent.com/79329387/130317906-4af5e0c7-4f5c-4a55-838b-3fdb21c5dda2.jpg)\n",
            "\n",
            " ​\n",
            "\n",
            "​\n",
            "\n",
            "​\n",
            "\n",
            "​\n",
            "\n",
            "![돌돌이그림](https://user-images.githubusercontent.com/79329387/130317939-15ae8a10-fa2a-4d04-8dce-9d63d16412c9.jpg)\n",
            "\n",
            "```python\n",
            "print('hello!')\n",
            "```\n",
            "\n",
            "​\n",
            "\n",
            "<br>\n",
            "\n",
            "<br>\n",
            "\n",
            "<br>\n",
            "\n",
            "# 2021-08-20\n",
            "\n",
            "<br>\n",
            "\n",
            "## Python Basic\n",
            "\n",
            "​\n",
            "\n",
            "- Mark Down\n",
            "\n",
            "  헤더\n",
            "\n",
            "  > # h1 이름\n",
            "  >\n",
            "  > ## h2 이름\n",
            "  >\n",
            "  > ### h3 이름\n",
            "\n",
            "  > 목록\n",
            "  >\n",
            "  > - 목록 이름 1\n",
            "  > - 목록 이름 2\n",
            "  >   - 목록 이름 2-1\n",
            "  >   - 목록 이름 2-2\n",
            "  >\n",
            "  > 1. 목\n",
            " 세계의 여러분들\n",
            "남선우입니다\n",
            "\n",
            "제 전공은 컴퓨터공학이고 현재는 소프트웨어 개발자로 일하고 있습니다.\n",
            "\n",
            "컴퓨터공학을 전공하게 된 이유는 저의 첫 사랑이 컴퓨터와 프로그래밍이었기 때문입니다. 어렸을 때부터 새로운 기술과 컴퓨터 게임에 대한 열정이 있었고, 이러한 관심이 컴퓨터공학을 선택하는 계기가 되었습니다.\n",
            "\n",
            "현재는 주로 웹 개발을 하고 있으며, 언어는 주로 자바스크립트를 사용합니다. 또한 프레임워크를 이용하여 더욱 효율적이고 빠른 개발을 위해 노력하고 있습니다.\n",
            "\n",
            "제가 선택한\n",
            " 매일 프로그래밍 (www.madforprogramming.com)에서 매일 문제를 풀어보고 있는데요, 오늘은 \"FizzBuzz\" 문제를 해결하는 방법에 대해 이야기해보려고 합니다.\n",
            "\n",
            "\"FizzBuzz\" 문제는 1부터 100까지의 수를 순서대로 출력하는데, 3의 배수일 때는 \"Fizz\", 5의 배수일 때는 \"Buzz\", 3과 5의 공배수일 때는 \"FizzBuzz\"를 출력해야 합니다. 예를 들어, 15는 3과 5의 공배수이므로 \"FizzBuzz\"를 출력해야 합니다.\n",
            "\n",
            "이 문제를 해결하는 방법은 다양하지만, 가장 간단하게는 반복문을 사용하는 방법입니다. 하지만 좀 더 창의적이고 효율적인 방법으로 풀어보겠습니다.\n",
            "\n",
            "첫 번째 방법으로는\n",
            "2.62 초\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "\n",
        "# 이벤트 루프를 중첩하는 설정\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# 비동기 처리로 한 번만 호출하는 함수\n",
        "async def async_generate(llm):\n",
        "    resp = await llm.agenerate([\"안녕하세요!\"])\n",
        "    print(resp.generations[0][0].text)\n",
        "\n",
        "# 비동기 처리로 10회 호출하는 함수\n",
        "async def generate_concurrently():\n",
        "    llm = OpenAI(\n",
        "        model=\"gpt-3.5-turbo-instruct\",\n",
        "        temperature=0.9\n",
        "    )\n",
        "    tasks = [async_generate(llm) for _ in range(10)]\n",
        "    await asyncio.gather(*tasks)\n",
        "\n",
        "# 시간 측정 시작\n",
        "s = time.perf_counter()\n",
        "\n",
        "# 비동기 처리로 10회 호출\n",
        "asyncio.run(generate_concurrently())\n",
        "\n",
        "# 시간 측정 완료\n",
        "elapsed = time.perf_counter() - s\n",
        "print(f\"{elapsed:0.2f} 초\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "312b14d5-4221-468c-b1c5-0c699e39be25",
      "metadata": {
        "id": "312b14d5-4221-468c-b1c5-0c699e39be25"
      },
      "source": [
        "#### PromptTemplate 기본 사용법"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eabaf86e-a195-4971-8111-3ded9d525185",
      "metadata": {
        "id": "eabaf86e-a195-4971-8111-3ded9d525185",
        "outputId": "e2f7c505-b917-4fd4-c61d-1864958d6df4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "아이폰는 어느 회사에서 개발한 제품인가요？\n",
            "갤럭시는 어느 회사에서 개발한 제품인가요？\n"
          ]
        }
      ],
      "source": [
        "from langchain import PromptTemplate  #← PromptTemplate 가져오기\n",
        "\n",
        "prompt = PromptTemplate(  #← PromptTemplate 초기화하기\n",
        "    template=\"{product}는 어느 회사에서 개발한 제품인가요？\",  #← {product}라는 변수를 포함하는 프롬프트 작성하기\n",
        "    input_variables=[\n",
        "        \"product\"  #← product에 입력할 변수 지정\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(prompt.format(product=\"아이폰\"))\n",
        "print(prompt.format(product=\"갤럭시\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5b1539e-e393-4fef-99ec-b72b98198128",
      "metadata": {
        "id": "b5b1539e-e393-4fef-99ec-b72b98198128"
      },
      "source": [
        "입력 변수가 없는 프롬프트 템플릿 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "678b3895-8611-4586-b088-bd5725d8a909",
      "metadata": {
        "id": "678b3895-8611-4586-b088-bd5725d8a909",
        "outputId": "23507955-b291-427e-9de6-4ccf85bdea6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "멋진 동물이라고 하면?\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# 입력 변수가 없는 프롬프트 템플릿 만들기\n",
        "no_input_prompt = PromptTemplate(\n",
        "    input_variables=[],\n",
        "    template=\"멋진 동물이라고 하면?\"\n",
        ")\n",
        "\n",
        "# 프롬프트 생성\n",
        "print(no_input_prompt.format())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba8c5728-3794-48a0-9f8e-75011833f6ed",
      "metadata": {
        "id": "ba8c5728-3794-48a0-9f8e-75011833f6ed"
      },
      "source": [
        "하나의 입력 변수가 있는 프롬프트 템플릿 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90627301-9017-4db6-ad33-b67c6ee32c68",
      "metadata": {
        "id": "90627301-9017-4db6-ad33-b67c6ee32c68",
        "outputId": "d216825a-2dec-4a89-dcab-ef3394bd75a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "멋진 동물이라고 하면?\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# 하나의 입력 변수가 있는 프롬프트 템플릿 만들기\n",
        "one_input_prompt = PromptTemplate(\n",
        "    input_variables=[\"content\"],\n",
        "    template=\"멋진 {content}이라고 하면?\"\n",
        ")\n",
        "\n",
        "# 프롬프트 생성\n",
        "print(one_input_prompt.format(content=\"동물\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69343a95-6338-453b-a2e1-38aa7e5742d4",
      "metadata": {
        "id": "69343a95-6338-453b-a2e1-38aa7e5742d4"
      },
      "source": [
        "여러 개의 입력 변수가 있는 프롬프트 템플릿 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ea4c5ce-dd9a-4363-8f5b-465675918350",
      "metadata": {
        "id": "8ea4c5ce-dd9a-4363-8f5b-465675918350",
        "outputId": "18a1d5f6-3984-4b8e-ff6b-c06df9bc8df5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "멋진동물이라고 하면?\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# 여러 개의 입력 변수가 있는 프롬프트 템플릿 만들기\n",
        "multiple_input_prompt = PromptTemplate(\n",
        "    input_variables=[\"adjective\", \"content\"],\n",
        "    template=\"{adjective}{content}이라고 하면?\"\n",
        ")\n",
        "\n",
        "# 프롬프트 생성\n",
        "print(multiple_input_prompt.format(adjective=\"멋진\", content=\"동물\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45d42f6c-52b4-4d95-b5dc-cc8e995b04bf",
      "metadata": {
        "id": "45d42f6c-52b4-4d95-b5dc-cc8e995b04bf"
      },
      "source": [
        "프롬프트 템플릿 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbf51d4a-c549-491e-bc19-7177669e1d31",
      "metadata": {
        "id": "fbf51d4a-c549-491e-bc19-7177669e1d31",
        "outputId": "539bae62-1dae-4630-bddb-acd10533e91c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Q: foo\n",
            "A: bar\n",
            "\n",
            "Q: 1\n",
            "A: 2\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# jinja2를 이용한 프롬프트 템플릿 준비\n",
        "jinja2_prompt = PromptTemplate(\n",
        "    input_variables=[\"items\"],\n",
        "    template_format=\"jinja2\",\n",
        "    template=\"\"\"\n",
        "{% for item in items %}\n",
        "Q: {{ item.question }}\n",
        "A: {{ item.answer }}\n",
        "{% endfor %}\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# 프롬프트 생성\n",
        "items=[\n",
        "    {\"question\": \"foo\", \"answer\": \"bar\"},\n",
        "    {\"question\": \"1\", \"answer\": \"2\"}\n",
        "]\n",
        "print(jinja2_prompt.format(items=items))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10ba7c75-feb6-48b4-a415-c02fb3726ba0",
      "metadata": {
        "id": "10ba7c75-feb6-48b4-a415-c02fb3726ba0"
      },
      "source": [
        "Language models 과 PromptTemplate 함께 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c6202e6-2c9f-432b-b122-ef7bf8c7dfbb",
      "metadata": {
        "id": "3c6202e6-2c9f-432b-b122-ef7bf8c7dfbb",
        "outputId": "3010a9f2-46fb-4fdb-a850-dfab4c9c9920"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "아이폰은 미국의 애플(Apple)이 개발한 제품입니다.\n"
          ]
        }
      ],
      "source": [
        "from langchain import PromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "chat = ChatOpenAI(  #← 클라이언트 생성 및 chat에 저장\n",
        "    model=\"gpt-3.5-turbo\",  #← 호출할 모델 지정\n",
        ")\n",
        "\n",
        "prompt = PromptTemplate(  #← PromptTemplate을 작성\n",
        "    template=\"{product}는 어느 회사에서 개발한 제품인가요？\",  #← {product}라는 변수를 포함하는 프롬프트 작성하기\n",
        "    input_variables=[\n",
        "        \"product\"  #← product에 입력할 변수 지정\n",
        "    ]\n",
        ")\n",
        "\n",
        "result = chat( #← 실행\n",
        "    [\n",
        "        HumanMessage(content=prompt.format(product=\"아이폰\")),\n",
        "    ]\n",
        ")\n",
        "print(result.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62682515-0cfc-4bec-8a18-3af2a345fab3",
      "metadata": {
        "id": "62682515-0cfc-4bec-8a18-3af2a345fab3"
      },
      "source": [
        "#### PromptTemplate와 json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14ca8fae-a02f-4e11-84b6-83dfdb75b68c",
      "metadata": {
        "id": "14ca8fae-a02f-4e11-84b6-83dfdb75b68c"
      },
      "outputs": [],
      "source": [
        "# PromptTemplate를 JSON으로 변환\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate(template=\"{product}는 어느 회사에서 개발한 제품인가요？\", input_variables=[\"product\"])\n",
        "prompt_json = prompt.save(\"prompt.json\") #← PromptTemplate를 JSON으로 변환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b029443-080c-4bbe-ac87-f44af0b3dad7",
      "metadata": {
        "id": "1b029443-080c-4bbe-ac87-f44af0b3dad7",
        "outputId": "20e588de-8784-4c61-ab89-286a3d40d3df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iPhone는 어느 회사에서 개발한 제품인가요？\n"
          ]
        }
      ],
      "source": [
        "#← JSON에서 PromptTemplate를 로드\n",
        "\n",
        "from langchain.prompts import load_prompt\n",
        "\n",
        "loaded_prompt = load_prompt(\"prompt.json\") #← JSON에서 PromptTemplate를 로드\n",
        "\n",
        "print(loaded_prompt.format(product=\"iPhone\")) #← PromptTemplate를 사용해 문장 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81b2c4a5-8111-4dfd-89c6-455abf08438b",
      "metadata": {
        "id": "81b2c4a5-8111-4dfd-89c6-455abf08438b"
      },
      "source": [
        "#### 출력 예제가 포함된 프롬프트 만들기(ICL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ba5492a-eb11-4116-ad09-f532fbcdb1b2",
      "metadata": {
        "id": "6ba5492a-eb11-4116-ad09-f532fbcdb1b2",
        "outputId": "8ce75469-57af-4501-e50a-829bbf089cca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "formatted_prompt:  아래 문장부호가 빠진 입력에 문장부호를 추가하세요. 추가할 수 있는 문장부호는 ',', '.'입니다. 다른 문장부호는 추가하지 마세요.\n",
            "\n",
            "입력: 충청도의 계룡산 전라도의 내장산 강원도의 설악산은 모두 국립 공원이다\n",
            "출력: 충청도의 계룡산, 전라도의 내장산, 강원도의 설악산은 모두 국립 공원이다.\n",
            "\n",
            "입력: 집을 보러 가면 그 집이 내가 원하는 조건에 맞는지 살기에 편한지 망가진 곳은 없는지 확인해야 한다\n",
            "출력:\n",
            "result:  집을 보러 가면, 그 집이 내가 원하는 조건에 맞는지, 살기에 편한지, 망가진 곳은 없는지 확인해야 한다.\n"
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
        "from langchain.schema import HumanMessage, SystemMessage\n",
        "\n",
        "# 예제 입력과 출력 정의\n",
        "examples = [\n",
        "    {\n",
        "        \"input\": \"충청도의 계룡산 전라도의 내장산 강원도의 설악산은 모두 국립 공원이다\",  # 입력 예\n",
        "        \"output\": \"충청도의 계룡산, 전라도의 내장산, 강원도의 설악산은 모두 국립 공원이다.\"  # 출력 예\n",
        "    }\n",
        "]\n",
        "\n",
        "# PromptTemplate 준비\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"input\", \"output\"],  # input과 output을 입력 변수로 설정\n",
        "    template=\"입력: {input}\\n출력: {output}\",  # 템플릿\n",
        ")\n",
        "\n",
        "# FewShotPromptTemplate 준비\n",
        "few_shot_prompt = FewShotPromptTemplate(\n",
        "    examples=examples,  # 입력 예와 출력 예를 정의\n",
        "    example_prompt=prompt,  # FewShotPromptTemplate에 PromptTemplate를 전달\n",
        "    prefix=\"아래 문장부호가 빠진 입력에 문장부호를 추가하세요. 추가할 수 있는 문장부호는 ',', '.'입니다. 다른 문장부호는 추가하지 마세요.\",  # 지시어 추가하기\n",
        "    suffix=\"입력: {input_string}\\n출력:\",  # 출력 예의 입력 변수를 정의\n",
        "    input_variables=[\"input_string\"],  # FewShotPromptTemplate의 입력 변수를 설정\n",
        ")\n",
        "\n",
        "# ChatOpenAI 모델 인스턴스 생성 (최신 Chat 모델 사용)\n",
        "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "\n",
        "# FewShotPromptTemplate을 사용하여 프롬프트 작성\n",
        "formatted_prompt = few_shot_prompt.format(\n",
        "    input_string=\"집을 보러 가면 그 집이 내가 원하는 조건에 맞는지 살기에 편한지 망가진 곳은 없는지 확인해야 한다\"\n",
        ")\n",
        "\n",
        "# 모델 예측 수행\n",
        "messages = [\n",
        "    SystemMessage(content=\"아래 문장부호가 빠진 입력에 문장부호를 추가하세요. 추가할 수 있는 문장부호는 ',', '.'입니다. 다른 문장부호는 추가하지 마세요.\"),\n",
        "    HumanMessage(content=formatted_prompt)\n",
        "]\n",
        "\n",
        "result = chat_model(messages)\n",
        "\n",
        "# 결과 출력\n",
        "print(\"formatted_prompt: \", formatted_prompt)\n",
        "print(\"result: \", result.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff741862-42de-4857-a1c5-7474999d5a25",
      "metadata": {
        "id": "ff741862-42de-4857-a1c5-7474999d5a25"
      },
      "source": [
        "#### 답변 예시가 포함된 프롬프트 템플릿 또 다른 예"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1603c4c1-6ffa-4182-8f98-d231cc4d4ae2",
      "metadata": {
        "id": "1603c4c1-6ffa-4182-8f98-d231cc4d4ae2",
        "outputId": "9d6139d4-431a-4d1d-ec04-0bdf1a467b30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "모든 입력에 대한 반의어를 입력하세요\n",
            "\n",
            "入力: 明るい\n",
            "出力: 暗い\n",
            "\n",
            "入力: おもしろい\n",
            "出力: つまらない\n",
            "\n",
            "입력: 큰\n",
            "출력:\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import FewShotPromptTemplate\n",
        "\n",
        "# 답변 예시 준비\n",
        "examples = [\n",
        "    {\"input\": \"明るい\", \"output\": \"暗い\"},\n",
        "    {\"input\": \"おもしろい\", \"output\": \"つまらない\"},\n",
        "]\n",
        "\n",
        "# 프롬프트 템플릿 생성\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"input\",\"output\"],\n",
        "    template=\"入力: {input}\\n出力: {output}\",\n",
        ")\n",
        "\n",
        "# 답변 예시를 포함한 프롬프트 템플릿 만들기\n",
        "prompt_from_string_examples = FewShotPromptTemplate(\n",
        "    examples=examples, # 답변 예시\n",
        "    example_prompt=example_prompt, # 프롬프트 템플릿\n",
        "    prefix=\"모든 입력에 대한 반의어를 입력하세요\", # 접두사\n",
        "    suffix=\"입력: {adjective}\\n출력:\", # 접미사\n",
        "    input_variables=[\"adjective\"], # 입력 변수\n",
        "    example_separator=\"\\n\\n\" # 구분 기호\n",
        "\n",
        ")\n",
        "\n",
        "# 프롬프트 생성\n",
        "print(prompt_from_string_examples.format(adjective=\"큰\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c034eefc-6e36-4bee-8168-fb205f0bd93b",
      "metadata": {
        "id": "c034eefc-6e36-4bee-8168-fb205f0bd93b"
      },
      "source": [
        "#### 답변 예시 포함 프롬프트 템플릿 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3577cb20-541e-40e4-9037-f89ab43cc016",
      "metadata": {
        "id": "3577cb20-541e-40e4-9037-f89ab43cc016"
      },
      "source": [
        "LengthBasedExampleSelector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d81cf57-4c3f-48e5-9e9c-eb20cbc55436",
      "metadata": {
        "id": "3d81cf57-4c3f-48e5-9e9c-eb20cbc55436",
        "outputId": "2b6eecb3-8587-4e29-d827-0c0b7558f742"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "모든 입력에 대한 반의어를 입력하세요\n",
            "\n",
            "입력: 밝은\n",
            "출력: 어두운\n",
            "\n",
            "입력: 재미있는\n",
            "출력: 지루한\n",
            "\n",
            "입력: 큰\n",
            "출력:\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import FewShotPromptTemplate\n",
        "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
        "\n",
        "# 답변 예시 준비\n",
        "examples = [\n",
        "    {\"input\": \"밝은\", \"output\": \"어두운\"},\n",
        "    {\"input\": \"재미있는\", \"output\": \"지루한\"},\n",
        "    {\"input\": \"활기찬\", \"output\": \"무기력한\"},\n",
        "    {\"input\": \"높은\", \"output\": \"낮은\"},\n",
        "    {\"input\": \"빠른\", \"output\": \"느린\"},\n",
        "]\n",
        "\n",
        "# 프롬프트 템플릿 생성\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"input\",\"output\"],\n",
        "    template=\"입력: {input}\\n출력: {output}\",\n",
        ")\n",
        "\n",
        "# LengthBasedExampleSelector 생성\n",
        "example_selector = LengthBasedExampleSelector(\n",
        "    examples=examples, # 답변 예시\n",
        "    example_prompt=example_prompt, # 프롬프트 템플릿\n",
        "    max_length=10, # 문자열의 최대 길이\n",
        ")\n",
        "\n",
        "# FewShotPromptTemplate 생성\n",
        "prompt_from_string_examples = FewShotPromptTemplate(\n",
        "    example_selector=example_selector,  # ExampleSelector\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=\"모든 입력에 대한 반의어를 입력하세요\",\n",
        "    suffix=\"입력: {adjective}\\n출력:\",\n",
        "    input_variables=[\"adjective\"],\n",
        "    example_separator=\"\\n\\n\"\n",
        ")\n",
        "\n",
        "# 프롬프트 생성\n",
        "print(prompt_from_string_examples.format(adjective=\"큰\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7f81d59-e583-42f8-af54-d241552732e1",
      "metadata": {
        "id": "c7f81d59-e583-42f8-af54-d241552732e1"
      },
      "source": [
        "SemanticSimilarityExampleSelector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcbdad21-1b2b-4afc-b38b-f0f973d99192",
      "metadata": {
        "id": "fcbdad21-1b2b-4afc-b38b-f0f973d99192",
        "outputId": "1efaed28-97ac-4fbf-8b9a-007e8e082487"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_8338/4107087812.py:24: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  embeddings=OpenAIEmbeddings(), # 임베디드 생성 클래스\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "모든 입력에 대한 반의어를 입력하세요\n",
            "\n",
            "입력: 높은\n",
            "출력: 낮은\n",
            "\n",
            "입력: 재미있는\n",
            "출력: 지루한\n",
            "\n",
            "입력: 밝은\n",
            "출력: 어두운\n",
            "\n",
            "입력: 큰\n",
            "출력:\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.prompts import FewShotPromptTemplate\n",
        "\n",
        "# 답변 예시 준비\n",
        "examples = [\n",
        "    {\"input\": \"밝은\", \"output\": \"어두운\"},\n",
        "    {\"input\": \"재미있는\", \"output\": \"지루한\"},\n",
        "    {\"input\": \"활기찬\", \"output\": \"무기력한\"},\n",
        "    {\"input\": \"높은\", \"output\": \"낮은\"},\n",
        "    {\"input\": \"빠른\", \"output\": \"느린\"},\n",
        "]\n",
        "\n",
        "# 프롬프트 템플릿 생성\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"input\",\"output\"],\n",
        "    template=\"입력: {input}\\n출력: {output}\",\n",
        ")\n",
        "\n",
        "# SemanticSimilarityExampleSelector 생성\n",
        "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
        "    examples=examples, # 답변 예시\n",
        "    embeddings=OpenAIEmbeddings(), # 임베디드 생성 클래스\n",
        "    vectorstore_cls=FAISS, # 임베디드 유사 검색 클래스\n",
        "    k=3 # 답변 예시 개수\n",
        ")\n",
        "\n",
        "# FewShotPromptTemplate 생성\n",
        "prompt_from_string_examples = FewShotPromptTemplate(\n",
        "    example_selector=example_selector,  # ExampleSelector\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=\"모든 입력에 대한 반의어를 입력하세요\",\n",
        "    suffix=\"입력: {adjective}\\n출력:\",\n",
        "    input_variables=[\"adjective\"],\n",
        "    example_separator=\"\\n\\n\"\n",
        ")\n",
        "\n",
        "# 프롬프트 생성\n",
        "print(prompt_from_string_examples.format(adjective=\"큰\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcdfc85c-4c2b-4e27-a534-ff984e3851f9",
      "metadata": {
        "id": "dcdfc85c-4c2b-4e27-a534-ff984e3851f9"
      },
      "source": [
        "MaxMarginalRelevanceExampleSelector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95c57954-d720-42a8-aab1-6477c5d15384",
      "metadata": {
        "id": "95c57954-d720-42a8-aab1-6477c5d15384",
        "outputId": "f0e9d7d8-57c3-4c14-ab50-4af080392cb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "모든 입력에 대한 반의어를 입력하세요\n",
            "\n",
            "입력: 높은\n",
            "출력: 낮은\n",
            "\n",
            "입력: 재미있는\n",
            "출력: 지루한\n",
            "\n",
            "입력: 밝은\n",
            "출력: 어두운\n",
            "\n",
            "입력: 큰\n",
            "출력:\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts.example_selector import MaxMarginalRelevanceExampleSelector\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.prompts import FewShotPromptTemplate\n",
        "\n",
        "# 답변 예시 준비\n",
        "examples = [\n",
        "    {\"input\": \"밝은\", \"output\": \"어두운\"},\n",
        "    {\"input\": \"재미있는\", \"output\": \"지루한\"},\n",
        "    {\"input\": \"활기찬\", \"output\": \"무기력한\"},\n",
        "    {\"input\": \"높은\", \"output\": \"낮은\"},\n",
        "    {\"input\": \"빠른\", \"output\": \"느린\"},\n",
        "]\n",
        "\n",
        "# 프롬프트 템플릿 생성\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"input\",\"output\"],\n",
        "    template=\"입력: {input}\\n출력: {output}\",\n",
        ")\n",
        "\n",
        "# MaxMarginalRelevanceExampleSelector 생성\n",
        "example_selector = MaxMarginalRelevanceExampleSelector.from_examples(\n",
        "    examples=examples, # 답변 예시\n",
        "    embeddings=OpenAIEmbeddings(), # 임베디드 생성 클래스\n",
        "    vectorstore_cls=FAISS, # 임베디드 유사 검색 클래스\n",
        "    k=3 # 답변 예시 개수\n",
        ")\n",
        "\n",
        "# FewShotPromptTemplate 준비\n",
        "prompt_from_string_examples = FewShotPromptTemplate(\n",
        "    example_selector=example_selector,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=\"모든 입력에 대한 반의어를 입력하세요\",\n",
        "    suffix=\"입력: {adjective}\\n출력:\",\n",
        "    input_variables=[\"adjective\"],\n",
        "    example_separator=\"\\n\\n\"\n",
        "\n",
        ")\n",
        "\n",
        "# 프롬프트 생성\n",
        "print(prompt_from_string_examples.format(adjective=\"큰\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af7f158c-1932-45ba-b2d2-5856e779ebb2",
      "metadata": {
        "id": "af7f158c-1932-45ba-b2d2-5856e779ebb2"
      },
      "source": [
        "Hub로부터 Prompt 받아오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "765a2508-bfcc-45d5-8305-0ecaf2d6d34d",
      "metadata": {
        "id": "765a2508-bfcc-45d5-8305-0ecaf2d6d34d",
        "outputId": "96a6f5fd-b30a-42f9-a59b-7943a84e15fa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nh/miniconda3/envs/py310_langchain/lib/python3.10/site-packages/langsmith/client.py:323: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_variables=['context', 'question'] input_types={} partial_variables={} metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]\n"
          ]
        }
      ],
      "source": [
        "from langchain import hub\n",
        "\n",
        "# 가장 최신 버전의 프롬프트를 가져옵니다.\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "# 프롬프트 내용 출력\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c54d385-93c9-4e91-9dff-8e01a73200b5",
      "metadata": {
        "id": "2c54d385-93c9-4e91-9dff-8e01a73200b5",
        "outputId": "a77414d1-bb41-4e68-8535-2cbfc35aaa4d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nh/miniconda3/envs/py310_langchain/lib/python3.10/site-packages/langsmith/client.py:323: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 특정 버전의 프롬프트를 가져오려면 버전 해시를 지정하세요\n",
        "prompt = hub.pull(\"rlm/rag-prompt:50442af1\")\n",
        "prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a4e96a8-7e3c-45de-8f11-e6bd09fb9355",
      "metadata": {
        "id": "2a4e96a8-7e3c-45de-8f11-e6bd09fb9355"
      },
      "source": [
        "#### CommaSeparatedListOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7daf2fca-622d-47fb-a3fe-3c7e5b7f2146",
      "metadata": {
        "id": "7daf2fca-622d-47fb-a3fe-3c7e5b7f2146",
        "outputId": "0ed9175f-d002-4549-8e7d-51ccc014d594"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "대표 상품 => 아이폰\n",
            "대표 상품 => 아이패드\n",
            "대표 상품 => 맥북\n"
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.output_parsers import \\\n",
        "    CommaSeparatedListOutputParser  #← Output Parser인 CommaSeparatedListOutputParser를 가져옵니다.\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "output_parser = CommaSeparatedListOutputParser() #← CommaSeparatedListOutputParser 초기화\n",
        "\n",
        "chat = ChatOpenAI(model=\"gpt-3.5-turbo\", )\n",
        "\n",
        "result = chat(\n",
        "    [\n",
        "        HumanMessage(content=\"애플이 개발한 대표적인 제품 3개를 알려주세요\"),\n",
        "        HumanMessage(content=output_parser.get_format_instructions()),  #← output_parser.get_format_instructions()를 실행하여 언어모델에 지시사항 추가하기\n",
        "    ]\n",
        ")\n",
        "\n",
        "output = output_parser.parse(result.content) #← 출력 결과를 분석하여 목록 형식으로 변환한다.\n",
        "\n",
        "for item in output: #← 목록을 하나씩 꺼내어 출력한다.\n",
        "    print(\"대표 상품 => \" + item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43e754e9-a9ce-41fc-bf86-fc9363c43603",
      "metadata": {
        "id": "43e754e9-a9ce-41fc-bf86-fc9363c43603",
        "outputId": "b755cbc1-b33f-42f5-804a-d0b6c6712b0f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['경복궁', '인사동', '남산타워', '부산 해운대해수욕장', '제주도']"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# 콤마로 구분된 리스트 출력 파서 초기화\n",
        "output_parser = CommaSeparatedListOutputParser()\n",
        "\n",
        "# 출력 형식 지침 가져오기\n",
        "format_instructions = output_parser.get_format_instructions()\n",
        "# 프롬프트 템플릿 설정\n",
        "prompt = PromptTemplate(\n",
        "    # 주제에 대한 다섯 가지를 나열하라는 템플릿\n",
        "    template=\"List five {subject}.\\n{format_instructions}\",\n",
        "    input_variables=[\"subject\"],  # 입력 변수로 'subject' 사용\n",
        "    # 부분 변수로 형식 지침 사용\n",
        "    partial_variables={\"format_instructions\": format_instructions},\n",
        ")\n",
        "\n",
        "# ChatOpenAI 모델 초기화\n",
        "model = ChatOpenAI(temperature=0)\n",
        "\n",
        "# 프롬프트, 모델, 출력 파서를 연결하여 체인 생성\n",
        "chain = prompt | model | output_parser\n",
        "\n",
        "# \"대한민국 관광명소\"에 대한 체인 호출 실행\n",
        "chain.invoke({\"subject\": \"대한민국 관광명소\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4098b18e-d49c-4459-bd50-9832f656c6f3",
      "metadata": {
        "id": "4098b18e-d49c-4459-bd50-9832f656c6f3",
        "outputId": "7ff9caa3-1aff-44b4-b98d-a00a40777b3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['경복궁']\n",
            "['남산타워']\n",
            "['부산 해운대해수욕장']\n",
            "['제주도']\n",
            "['경주여행']\n"
          ]
        }
      ],
      "source": [
        "# 스트림을 순회합니다.\n",
        "for s in chain.stream({\"subject\": \"대한민국 관광명소\"}):\n",
        "    print(s)  # 스트림의 내용을 출력합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71b20532-a3a1-4519-8abf-27d1767ebfb9",
      "metadata": {
        "id": "71b20532-a3a1-4519-8abf-27d1767ebfb9"
      },
      "source": [
        "#### Pydantic 출력 파서(PydanticOutputParser)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95e3c596-820d-431b-aacf-6c5efdd92710",
      "metadata": {
        "id": "95e3c596-820d-431b-aacf-6c5efdd92710"
      },
      "source": [
        "이메일 본문 예시"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a708932-7e72-4948-bc4e-1e5016ad593b",
      "metadata": {
        "id": "9a708932-7e72-4948-bc4e-1e5016ad593b"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "from pydantic import BaseModel, Field  # Pydantic v2 사용\n",
        "\n",
        "# LLM 모델 설정\n",
        "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4\")\n",
        "\n",
        "# 이메일 대화 샘플\n",
        "email_conversation = \"\"\"From: 홍길동 (gildong@bc.com)\n",
        "To: 김대경 (kz4network@naver.com)\n",
        "Subject: \"ZENESIS\" 자전거 유통 협력 및 미팅 일정 제안\n",
        "\n",
        "안녕하세요, 이은채 대리님,\n",
        "\n",
        "저는 바이크코퍼레이션의 김철수 상무입니다. 최근 보도자료를 통해 귀사의 신규 자전거 \"ZENESIS\"에 대해 알게 되었습니다. 바이크코퍼레이션은 자전거 제조 및 유통 분야에서 혁신과 품질을 선도하는 기업으로, 이 분야에서의 장기적인 경험과 전문성을 가지고 있습니다.\n",
        "\n",
        "ZENESIS 모델에 대한 상세한 브로슈어를 요청드립니다. 특히 기술 사양, 배터리 성능, 그리고 디자인 측면에 대한 정보가 필요합니다. 이를 통해 저희가 제안할 유통 전략과 마케팅 계획을 보다 구체화할 수 있을 것입니다.\n",
        "\n",
        "또한, 협력 가능성을 더 깊이 논의하기 위해 다음 주 화요일(1월 15일) 오전 10시에 미팅을 제안합니다. 귀사 사무실에서 만나 이야기를 나눌 수 있을까요?\n",
        "\n",
        "감사합니다.\n",
        "\n",
        "김철수\n",
        "상무이사\n",
        "바이크코퍼레이션\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bd96a81-a34f-4162-b0a5-e20100486248",
      "metadata": {
        "id": "8bd96a81-a34f-4162-b0a5-e20100486248"
      },
      "source": [
        "출력 파서를 사용하지 않는 경우 예시"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43e140df-eea5-4d5d-a949-57b43a8fa9a7",
      "metadata": {
        "id": "43e140df-eea5-4d5d-a949-57b43a8fa9a7",
        "outputId": "a3acd7b5-5c00-44e0-e362-495f7eecd5c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "다음은 이메일의 중요한 내용입니다:\n",
            "\n",
            "1. **요청 사항**:\n",
            "   - ZENESIS 모델에 대한 상세한 브로슈어 요청 (기술 사양, 배터리 성능, 디자인 정보 포함).\n",
            "\n",
            "2. **미팅 제안**:\n",
            "   - 다음 주 화요일(1월 15일) 오전 10시에 미팅 제안.\n",
            "   - 미팅 장소: 귀사 사무실.\n",
            "\n",
            "3. **목적**:\n",
            "   - ZENESIS 자전거 유통 협력 논의.\n",
            "   - 유통 전략과 마케팅 계획 구체화.\n",
            "\n",
            "최종 출력: 다음은 이메일의 중요한 내용입니다:\n",
            "\n",
            "1. **요청 사항**:\n",
            "   - ZENESIS 모델에 대한 상세한 브로슈어 요청 (기술 사양, 배터리 성능, 디자인 정보 포함).\n",
            "\n",
            "2. **미팅 제안**:\n",
            "   - 다음 주 화요일(1월 15일) 오전 10시에 미팅 제안.\n",
            "   - 미팅 장소: 귀사 사무실.\n",
            "\n",
            "3. **목적**:\n",
            "   - ZENESIS 자전거 유통 협력 논의.\n",
            "   - 유통 전략과 마케팅 계획 구체화.\n"
          ]
        }
      ],
      "source": [
        "from itertools import chain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# PromptTemplate 설정\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"다음의 이메일 내용 중 중요한 내용을 추출해 주세요.\\n\\n{email_conversation}\"\n",
        ")\n",
        "\n",
        "# LLM 설정\n",
        "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "\n",
        "# Prompt와 LLM 체인 구성\n",
        "chain = prompt | llm\n",
        "\n",
        "# 스트리밍 응답 받기\n",
        "answer = chain.stream({\"email_conversation\": email_conversation})\n",
        "\n",
        "# 스트리밍 응답을 출력하는 함수 직접 구현\n",
        "def stream_response(answer):\n",
        "    full_output = \"\"\n",
        "    for chunk in answer:\n",
        "        content = chunk.content  # AIMessageChunk에서 내용을 추출\n",
        "        print(content, end=\"\", flush=True)  # 실시간 출력\n",
        "        full_output += content  # 스트리밍 전체 결과를 저장\n",
        "    return full_output\n",
        "\n",
        "# 스트리밍 응답 처리 및 전체 결과 저장\n",
        "output = stream_response(answer)\n",
        "\n",
        "# 전체 출력 확인\n",
        "print(\"\\n\\n최종 출력:\", output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c404a89-0f76-4a6c-a0a5-37a31e113437",
      "metadata": {
        "id": "9c404a89-0f76-4a6c-a0a5-37a31e113437"
      },
      "source": [
        "Pydantic 스타일로 정의된 클래스를 사용하여 이메일의 정보를 파싱"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "996738bc-0d22-47e1-b1c9-bbe103839425",
      "metadata": {
        "id": "996738bc-0d22-47e1-b1c9-bbe103839425",
        "outputId": "f66944eb-e891-4b72-af15-3a71538ff02a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"properties\": {\"person\": {\"description\": \"메일을 보낸 사람\", \"title\": \"Person\", \"type\": \"string\"}, \"email\": {\"description\": \"메일을 보낸 사람의 이메일 주소\", \"title\": \"Email\", \"type\": \"string\"}, \"subject\": {\"description\": \"메일 제목\", \"title\": \"Subject\", \"type\": \"string\"}, \"summary\": {\"description\": \"메일 본문을 요약한 텍스트\", \"title\": \"Summary\", \"type\": \"string\"}, \"date\": {\"description\": \"메일 본문에 언급된 미팅 날짜와 시간\", \"title\": \"Date\", \"type\": \"string\"}}, \"required\": [\"person\", \"email\", \"subject\", \"summary\", \"date\"]}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "class EmailSummary(BaseModel):\n",
        "    person: str = Field(description=\"메일을 보낸 사람\")\n",
        "    email: str = Field(description=\"메일을 보낸 사람의 이메일 주소\")\n",
        "    subject: str = Field(description=\"메일 제목\")\n",
        "    summary: str = Field(description=\"메일 본문을 요약한 텍스트\")\n",
        "    date: str = Field(description=\"메일 본문에 언급된 미팅 날짜와 시간\")\n",
        "\n",
        "\n",
        "# PydanticOutputParser 생성\n",
        "parser = PydanticOutputParser(pydantic_object=EmailSummary)\n",
        "\n",
        "# instruction 을 출력합니다.\n",
        "print(parser.get_format_instructions())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "232f9802-1b64-4e0f-812c-cc1e7ab6f838",
      "metadata": {
        "id": "232f9802-1b64-4e0f-812c-cc1e7ab6f838"
      },
      "outputs": [],
      "source": [
        "prompt = PromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "You are a helpful assistant. Please answer the following questions in KOREAN.\n",
        "\n",
        "QUESTION:\n",
        "{question}\n",
        "\n",
        "EMAIL CONVERSATION:\n",
        "{email_conversation}\n",
        "\n",
        "FORMAT:\n",
        "{format}\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# format 에 PydanticOutputParser의 부분 포맷팅(partial) 추가\n",
        "prompt = prompt.partial(format=parser.get_format_instructions())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d9d038f-2d3c-4735-888e-dbc56632dc4c",
      "metadata": {
        "id": "2d9d038f-2d3c-4735-888e-dbc56632dc4c"
      },
      "outputs": [],
      "source": [
        "# chain 을 생성합니다.\n",
        "chain = prompt | llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18cccabd-642e-4a84-9387-b5d955b181c0",
      "metadata": {
        "id": "18cccabd-642e-4a84-9387-b5d955b181c0",
        "outputId": "4602d133-7e5b-435d-8a71-b67a5d917ef9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```json\n",
            "{\n",
            "  \"person\": \"김철수\",\n",
            "  \"email\": \"gildong@bc.com\",\n",
            "  \"subject\": \"\\\"ZENESIS\\\" 자전거 유통 협력 및 미팅 일정 제안\",\n",
            "  \"summary\": \"바이크코퍼레이션의 김철수 상무가 ZENESIS 자전거 모델에 대한 상세한 브로슈어를 요청하며, 유통 전략과 마케팅 계획을 구체화하기 위해 다음 주 화요일(1월 15일) 오전 10시에 미팅을 제안합니다.\",\n",
            "  \"date\": \"1월 15일 오전 10시\"\n",
            "}\n",
            "```"
          ]
        }
      ],
      "source": [
        "# chain 을 실행하고 결과를 출력합니다.\n",
        "response = chain.stream(\n",
        "    {\n",
        "        \"email_conversation\": email_conversation,\n",
        "        \"question\": \"이메일 내용중 주요 내용을 추출해 주세요.\",\n",
        "    }\n",
        ")\n",
        "\n",
        "# 결과는 JSON 형태로 출력됩니다.\n",
        "output = stream_response(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e997b51e-3a27-4c84-a664-b31d22ba8bd5",
      "metadata": {
        "id": "e997b51e-3a27-4c84-a664-b31d22ba8bd5",
        "outputId": "76b1e8dd-f476-46e4-f6b4-ede585f7f684"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "person='김철수' email='gildong@bc.com' subject='\"ZENESIS\" 자전거 유통 협력 및 미팅 일정 제안' summary='바이크코퍼레이션의 김철수 상무가 ZENESIS 자전거 모델에 대한 상세한 브로슈어를 요청하며, 유통 전략과 마케팅 계획을 구체화하기 위해 다음 주 화요일(1월 15일) 오전 10시에 미팅을 제안합니다.' date='1월 15일 오전 10시'\n"
          ]
        }
      ],
      "source": [
        "# PydanticOutputParser 를 사용하여 결과를 파싱합니다.\n",
        "structured_output = parser.parse(output)\n",
        "print(structured_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bd2d54d-bbba-4609-84be-bb7fa4efb404",
      "metadata": {
        "id": "8bd2d54d-bbba-4609-84be-bb7fa4efb404"
      },
      "source": [
        "parser 가 추가된 체인 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "791e1e57-84dd-42b9-9491-9a179bc42b4c",
      "metadata": {
        "id": "791e1e57-84dd-42b9-9491-9a179bc42b4c"
      },
      "outputs": [],
      "source": [
        "# 출력 파서를 추가하여 전체 체인을 재구성합니다.\n",
        "chain = prompt | llm | parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b2d31ad-6582-4ee7-8c60-1833b4e39cf8",
      "metadata": {
        "id": "3b2d31ad-6582-4ee7-8c60-1833b4e39cf8",
        "outputId": "eee6b9fa-6009-454b-e823-15df7f04f3f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "EmailSummary(person='김철수', email='gildong@bc.com', subject='\"ZENESIS\" 자전거 유통 협력 및 미팅 일정 제안', summary='바이크코퍼레이션의 김철수 상무가 ZENESIS 자전거 모델에 대한 상세한 브로슈어를 요청하며, 유통 전략과 마케팅 계획을 구체화하기 위해 다음 주 화요일(1월 15일) 오전 10시에 미팅을 제안합니다.', date='1월 15일 오전 10시')"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# chain 을 실행하고 결과를 출력합니다.\n",
        "response = chain.invoke(\n",
        "    {\n",
        "        \"email_conversation\": email_conversation,\n",
        "        \"question\": \"이메일 내용중 주요 내용을 추출해 주세요.\",\n",
        "    }\n",
        ")\n",
        "\n",
        "# 결과는 EmailSummary 객체 형태로 출력됩니다.\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdf2cb77-823a-40e6-a334-7235103fe2e7",
      "metadata": {
        "id": "cdf2cb77-823a-40e6-a334-7235103fe2e7"
      },
      "source": [
        "with_structured_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "084fae0b-0459-4ef7-8297-4ab8ca9e9662",
      "metadata": {
        "id": "084fae0b-0459-4ef7-8297-4ab8ca9e9662"
      },
      "outputs": [],
      "source": [
        "llm_with_structered = ChatOpenAI(\n",
        "    temperature=0, model_name=\"gpt-4o\"\n",
        ").with_structured_output(EmailSummary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "234e79f1-e572-4607-9380-cafdeb62066a",
      "metadata": {
        "id": "234e79f1-e572-4607-9380-cafdeb62066a",
        "outputId": "6844193c-1c66-4f9b-98bb-45dee15407e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "EmailSummary(person='홍길동', email='gildong@bc.com', subject='\"ZENESIS\" 자전거 유통 협력 및 미팅 일정 제안', summary='바이크코퍼레이션의 김철수 상무가 ZENESIS 자전거 모델에 대한 브로슈어 요청 및 유통 협력 가능성을 논의하기 위해 미팅을 제안합니다.', date='1월 15일 오전 10시')"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# invoke() 함수를 호출하여 결과를 출력합니다.\n",
        "answer = llm_with_structered.invoke(email_conversation)\n",
        "answer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90cd69b1-2ffb-4c99-98c6-0aff4ffba7d5",
      "metadata": {
        "id": "90cd69b1-2ffb-4c99-98c6-0aff4ffba7d5"
      },
      "source": [
        "#### 구조화된 출력 파서(StructuredOuputParser)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c65825cf-268c-474c-a794-621b6ceb77c0",
      "metadata": {
        "id": "c65825cf-268c-474c-a794-621b6ceb77c0"
      },
      "outputs": [],
      "source": [
        "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# 사용자의 질문에 대한 답변\n",
        "response_schemas = [\n",
        "    ResponseSchema(name=\"answer\", description=\"사용자의 질문에 대한 답변\"),\n",
        "    ResponseSchema(\n",
        "        name=\"source\",\n",
        "        description=\"사용자의 질문에 답하기 위해 사용된 `출처`, `웹사이트주소` 이여야 합니다.\",\n",
        "    ),\n",
        "]\n",
        "# 응답 스키마를 기반으로 한 구조화된 출력 파서 초기화\n",
        "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45a77a2c-0852-4ddd-b94a-9ecd4568df51",
      "metadata": {
        "id": "45a77a2c-0852-4ddd-b94a-9ecd4568df51",
        "outputId": "86d18061-f13c-4ca3-9e51-af0ba7d54ee8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'answer': '서울', 'source': 'https://ko.wikipedia.org/wiki/%EC%84%9C%EC%9A%B8'}"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 출력 형식 지시사항을 파싱합니다.\n",
        "format_instructions = output_parser.get_format_instructions()\n",
        "prompt = PromptTemplate(\n",
        "    # 사용자의 질문에 최대한 답변하도록 템플릿을 설정합니다.\n",
        "    template=\"answer the users question as best as possible.\\n{format_instructions}\\n{question}\",\n",
        "    # 입력 변수로 'question'을 사용합니다.\n",
        "    input_variables=[\"question\"],\n",
        "    # 부분 변수로 'format_instructions'을 사용합니다.\n",
        "    partial_variables={\"format_instructions\": format_instructions},\n",
        ")\n",
        "\n",
        "model = ChatOpenAI(temperature=0)  # ChatOpenAI 모델 초기화\n",
        "chain = prompt | model | output_parser  # 프롬프트, 모델, 출력 파서를 연결\n",
        "\n",
        "# 대한민국의 수도가 무엇인지 질문합니다.\n",
        "chain.invoke({\"question\": \"대한민국의 수도는 어디인가요?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a7ab877-b6d8-469f-9c32-203d21f6de22",
      "metadata": {
        "id": "4a7ab877-b6d8-469f-9c32-203d21f6de22",
        "outputId": "c768c2ca-ea84-4a96-9862-bc28eabc8334"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'answer': '세종대왕은 한글을 창제하고 문화를 발전시키는 등 다양한 업적을 가졌습니다.', 'source': 'https://ko.wikipedia.org/wiki/%EC%84%B8%EC%A2%85%EB%8C%80%EC%99%95'}\n"
          ]
        }
      ],
      "source": [
        "for s in chain.stream({\"question\": \"세종대왕의 업적은 무엇인가요?\"}):\n",
        "    # 스트리밍 출력\n",
        "    print(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c6bc9e7-8242-490a-8b8d-41967c3b5786",
      "metadata": {
        "id": "2c6bc9e7-8242-490a-8b8d-41967c3b5786"
      },
      "source": [
        "#### JSON 출력 파서(JsonOutputParser)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e92467b-3140-4378-a936-d2b36397082f",
      "metadata": {
        "id": "2e92467b-3140-4378-a936-d2b36397082f"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from pydantic import BaseModel, Field  # 최신 버전의 pydantic import\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# OpenAI 객체를 생성합니다.\n",
        "model = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0343eaad-891e-468b-9495-0ae379520df4",
      "metadata": {
        "id": "0343eaad-891e-468b-9495-0ae379520df4"
      },
      "outputs": [],
      "source": [
        "# 원하는 데이터 구조를 정의합니다.\n",
        "class Topic(BaseModel):\n",
        "    description: str = Field(description=\"주제에 대한 간결한 설명\")\n",
        "    hashtags: str = Field(description=\"해시태그 형식의 키워드(2개 이상)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8c8c0bd-6c35-496a-bcfa-9535888e3ccc",
      "metadata": {
        "id": "b8c8c0bd-6c35-496a-bcfa-9535888e3ccc",
        "outputId": "18dbe446-aa6c-4818-f709-488dd3aac74b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'description': '지구 온난화는 지구의 평균 기온이 지속적으로 상승하는 현상으로, 이는 주로 인간 활동에 의해 발생하는 온실가스 배출로 인해 발생합니다. 이로 인해 극지방의 빙하가 녹고 해수면이 상승하며, 기후 패턴이 변화하고 있습니다. 이러한 변화는 생태계와 인간 사회에 심각한 영향을 미치고 있습니다.', 'hashtags': '#지구온난화 #기후변화 #온실가스 #환경보호'}\n"
          ]
        }
      ],
      "source": [
        "# 질의 작성\n",
        "question = \"지구 온난화의 심각성 대해 알려주세요.\"\n",
        "\n",
        "# 파서를 설정하고 프롬프트 템플릿에 지시사항을 주입합니다.\n",
        "parser = JsonOutputParser(pydantic_object=Topic)\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"당신은 친절한 AI 어시스턴트 입니다. 질문에 간결하게 답변하세요.\"),\n",
        "        (\"user\", \"#Format: {format_instructions}\\n\\n#Question: {question}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 최신 Pydantic 버전에 맞게 format_instructions 가져오기\n",
        "prompt = prompt.partial(format_instructions=parser.get_format_instructions())\n",
        "\n",
        "# 체인을 구성합니다.\n",
        "chain = prompt | model | parser\n",
        "\n",
        "# 체인을 호출하여 쿼리 실행\n",
        "output = chain.invoke({\"question\": question})\n",
        "\n",
        "# 결과 출력\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b93b5510-d4f1-43b0-a904-a234f7eb34cc",
      "metadata": {
        "id": "b93b5510-d4f1-43b0-a904-a234f7eb34cc"
      },
      "source": [
        "Pydantic 없이 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "930072b2-82fa-4747-ba56-c5eb5cf1d863",
      "metadata": {
        "id": "930072b2-82fa-4747-ba56-c5eb5cf1d863",
        "outputId": "4c199f5a-0093-4c91-e923-a1c96105745c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'description': '지구 온난화는 대기 중 온실가스 농도의 증가로 인해 지구의 평균 기온이 상승하는 현상을 말합니다. 이는 주로 화석 연료의 연소, 산림 파괴, 산업 활동 등 인간의 활동에 의해 발생합니다. 지구 온난화는 기후 변화, 해수면 상승, 생태계 파괴 등 다양한 환경 문제를 초래합니다.', 'hashtags': ['#지구온난화', '#기후변화', '#온실가스', '#환경문제', '#해수면상승']}\n"
          ]
        }
      ],
      "source": [
        "# 질의 작성\n",
        "question = \"지구 온난화에 대해 알려주세요. 온난화에 대한 설명은 `description`에, 관련 키워드는 `hashtags`에 담아주세요.\"\n",
        "\n",
        "# JSON 출력 파서 초기화\n",
        "parser = JsonOutputParser()\n",
        "\n",
        "# 프롬프트 템플릿을 설정합니다.\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"당신은 친절한 AI 어시스턴트 입니다. 질문에 간결하게 답변하세요.\"),\n",
        "        (\"user\", \"#Format: {format_instructions}\\n\\n#Question: {question}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 지시사항을 프롬프트에 주입합니다.\n",
        "prompt = prompt.partial(format_instructions=parser.get_format_instructions())\n",
        "\n",
        "# 프롬프트, 모델, 파서를 연결하는 체인 생성\n",
        "chain = prompt | model | parser\n",
        "\n",
        "# 체인을 호출하여 쿼리 실행\n",
        "response = chain.invoke({\"question\": question})\n",
        "\n",
        "# 출력을 확인합니다.\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a48f8b3a-d795-4a7a-b169-fbdd195a2308",
      "metadata": {
        "id": "a48f8b3a-d795-4a7a-b169-fbdd195a2308"
      },
      "source": [
        "#### PandasDataFrameOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d7528cf-9b05-4a2c-939d-6fc6a186cf6e",
      "metadata": {
        "id": "4d7528cf-9b05-4a2c-939d-6fc6a186cf6e"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "from typing import Any, Dict\n",
        "\n",
        "import pandas as pd\n",
        "from langchain.output_parsers import PandasDataFrameOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# ChatOpenAI 모델 초기화 (gpt-3.5-turbo 모델 사용을 권장합니다)\n",
        "model = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a328118-379c-452e-81d1-dcbd9e53fb27",
      "metadata": {
        "id": "2a328118-379c-452e-81d1-dcbd9e53fb27"
      },
      "outputs": [],
      "source": [
        "# 출력 목적으로만 사용됩니다.\n",
        "def format_parser_output(parser_output: Dict[str, Any]) -> None:\n",
        "    # 파서 출력의 키들을 순회합니다.\n",
        "    for key in parser_output.keys():\n",
        "        # 각 키의 값을 딕셔너리로 변환합니다.\n",
        "        parser_output[key] = parser_output[key].to_dict()\n",
        "    # 예쁘게 출력합니다.\n",
        "    return pprint.PrettyPrinter(width=4, compact=True).pprint(parser_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79f79776-741d-4b00-97c9-250c03c657f7",
      "metadata": {
        "id": "79f79776-741d-4b00-97c9-250c03c657f7",
        "outputId": "a69eb8f9-9eee-41e0-aefd-35c0d50682c9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "4            5         0       3   \n",
              "\n",
              "                                                Name  Gender   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                           Allen, Mr. William Henry    male  35.0      0   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  \n",
              "0      0         A/5 21171   7.2500   NaN        S  \n",
              "1      0          PC 17599  71.2833   C85        C  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "3      0            113803  53.1000  C123        S  \n",
              "4      0            373450   8.0500   NaN        S  "
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 원하는 Pandas DataFrame을 정의합니다.\n",
        "df = pd.read_csv(\"./datasets/titanic.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99b47db1-3b32-4f08-baa5-6a254c2ed615",
      "metadata": {
        "id": "99b47db1-3b32-4f08-baa5-6a254c2ed615",
        "outputId": "d956436b-9c18-4222-99b6-5eae6823f8a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The output should be formatted as a string as the operation, followed by a colon, followed by the column or row to be queried on, followed by optional array parameters.\n",
            "1. The column names are limited to the possible columns below.\n",
            "2. Arrays must either be a comma-separated list of numbers formatted as [1,3,5], or it must be in range of numbers formatted as [0..4].\n",
            "3. Remember that arrays are optional and not necessarily required.\n",
            "4. If the column is not in the possible columns or the operation is not a valid Pandas DataFrame operation, return why it is invalid as a sentence starting with either \"Invalid column\" or \"Invalid operation\".\n",
            "\n",
            "As an example, for the formats:\n",
            "1. String \"column:num_legs\" is a well-formatted instance which gets the column num_legs, where num_legs is a possible column.\n",
            "2. String \"row:1\" is a well-formatted instance which gets row 1.\n",
            "3. String \"column:num_legs[1,2]\" is a well-formatted instance which gets the column num_legs for rows 1 and 2, where num_legs is a possible column.\n",
            "4. String \"row:1[num_legs]\" is a well-formatted instance which gets row 1, but for just column num_legs, where num_legs is a possible column.\n",
            "5. String \"mean:num_legs[1..3]\" is a well-formatted instance which takes the mean of num_legs from rows 1 to 3, where num_legs is a possible column and mean is a valid Pandas DataFrame operation.\n",
            "6. String \"do_something:num_legs\" is a badly-formatted instance, where do_something is not a valid Pandas DataFrame operation.\n",
            "7. String \"mean:invalid_col\" is a badly-formatted instance, where invalid_col is not a possible column.\n",
            "\n",
            "Here are the possible columns:\n",
            "```\n",
            "PassengerId, Survived, Pclass, Name, Gender, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked\n",
            "```\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 파서를 설정하고 프롬프트 템플릿에 지시사항을 주입합니다.\n",
        "parser = PandasDataFrameOutputParser(dataframe=df)\n",
        "\n",
        "# 파서의 지시사항을 출력합니다.\n",
        "print(parser.get_format_instructions())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "693a273b-5d6e-4733-8a68-67778f096246",
      "metadata": {
        "id": "693a273b-5d6e-4733-8a68-67778f096246"
      },
      "source": [
        "컬럼에 대한 값을 조회"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "098c9b9a-dd21-48a8-a8b5-abd656c9c5bb",
      "metadata": {
        "id": "098c9b9a-dd21-48a8-a8b5-abd656c9c5bb",
        "outputId": "d006992f-ac2f-473d-d11e-28d046246a8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Age': {0: 22.0,\n",
            "         1: 38.0,\n",
            "         2: 26.0,\n",
            "         3: 35.0,\n",
            "         4: 35.0,\n",
            "         5: nan,\n",
            "         6: 54.0,\n",
            "         7: 2.0,\n",
            "         8: 27.0,\n",
            "         9: 14.0,\n",
            "         10: 4.0,\n",
            "         11: 58.0,\n",
            "         12: 20.0,\n",
            "         13: 39.0,\n",
            "         14: 14.0,\n",
            "         15: 55.0,\n",
            "         16: 2.0,\n",
            "         17: nan,\n",
            "         18: 31.0,\n",
            "         19: nan,\n",
            "         20: 35.0,\n",
            "         21: 34.0,\n",
            "         22: 15.0,\n",
            "         23: 28.0,\n",
            "         24: 8.0,\n",
            "         25: 38.0,\n",
            "         26: nan,\n",
            "         27: 19.0,\n",
            "         28: nan,\n",
            "         29: nan,\n",
            "         30: 40.0,\n",
            "         31: nan,\n",
            "         32: nan,\n",
            "         33: 66.0,\n",
            "         34: 28.0,\n",
            "         35: 42.0,\n",
            "         36: nan,\n",
            "         37: 21.0,\n",
            "         38: 18.0,\n",
            "         39: 14.0,\n",
            "         40: 40.0,\n",
            "         41: 27.0,\n",
            "         42: nan,\n",
            "         43: 3.0,\n",
            "         44: 19.0,\n",
            "         45: nan,\n",
            "         46: nan,\n",
            "         47: nan,\n",
            "         48: nan,\n",
            "         49: 18.0,\n",
            "         50: 7.0,\n",
            "         51: 21.0,\n",
            "         52: 49.0,\n",
            "         53: 29.0,\n",
            "         54: 65.0,\n",
            "         55: nan,\n",
            "         56: 21.0,\n",
            "         57: 28.5,\n",
            "         58: 5.0,\n",
            "         59: 11.0,\n",
            "         60: 22.0,\n",
            "         61: 38.0,\n",
            "         62: 45.0,\n",
            "         63: 4.0,\n",
            "         64: nan,\n",
            "         65: nan,\n",
            "         66: 29.0,\n",
            "         67: 19.0,\n",
            "         68: 17.0,\n",
            "         69: 26.0,\n",
            "         70: 32.0,\n",
            "         71: 16.0,\n",
            "         72: 21.0,\n",
            "         73: 26.0,\n",
            "         74: 32.0,\n",
            "         75: 25.0,\n",
            "         76: nan,\n",
            "         77: nan,\n",
            "         78: 0.83,\n",
            "         79: 30.0,\n",
            "         80: 22.0,\n",
            "         81: 29.0,\n",
            "         82: nan,\n",
            "         83: 28.0,\n",
            "         84: 17.0,\n",
            "         85: 33.0,\n",
            "         86: 16.0,\n",
            "         87: nan,\n",
            "         88: 23.0,\n",
            "         89: 24.0,\n",
            "         90: 29.0,\n",
            "         91: 20.0,\n",
            "         92: 46.0,\n",
            "         93: 26.0,\n",
            "         94: 59.0,\n",
            "         95: nan,\n",
            "         96: 71.0,\n",
            "         97: 23.0,\n",
            "         98: 34.0,\n",
            "         99: 34.0,\n",
            "         100: 28.0,\n",
            "         101: nan,\n",
            "         102: 21.0,\n",
            "         103: 33.0,\n",
            "         104: 37.0,\n",
            "         105: 28.0,\n",
            "         106: 21.0,\n",
            "         107: nan,\n",
            "         108: 38.0,\n",
            "         109: nan,\n",
            "         110: 47.0,\n",
            "         111: 14.5,\n",
            "         112: 22.0,\n",
            "         113: 20.0,\n",
            "         114: 17.0,\n",
            "         115: 21.0,\n",
            "         116: 70.5,\n",
            "         117: 29.0,\n",
            "         118: 24.0,\n",
            "         119: 2.0,\n",
            "         120: 21.0,\n",
            "         121: nan,\n",
            "         122: 32.5,\n",
            "         123: 32.5,\n",
            "         124: 54.0,\n",
            "         125: 12.0,\n",
            "         126: nan,\n",
            "         127: 24.0,\n",
            "         128: nan,\n",
            "         129: 45.0,\n",
            "         130: 33.0,\n",
            "         131: 20.0,\n",
            "         132: 47.0,\n",
            "         133: 29.0,\n",
            "         134: 25.0,\n",
            "         135: 23.0,\n",
            "         136: 19.0,\n",
            "         137: 37.0,\n",
            "         138: 16.0,\n",
            "         139: 24.0,\n",
            "         140: nan,\n",
            "         141: 22.0,\n",
            "         142: 24.0,\n",
            "         143: 19.0,\n",
            "         144: 18.0,\n",
            "         145: 19.0,\n",
            "         146: 27.0,\n",
            "         147: 9.0,\n",
            "         148: 36.5,\n",
            "         149: 42.0,\n",
            "         150: 51.0,\n",
            "         151: 22.0,\n",
            "         152: 55.5,\n",
            "         153: 40.5,\n",
            "         154: nan,\n",
            "         155: 51.0,\n",
            "         156: 16.0,\n",
            "         157: 30.0,\n",
            "         158: nan,\n",
            "         159: nan,\n",
            "         160: 44.0,\n",
            "         161: 40.0,\n",
            "         162: 26.0,\n",
            "         163: 17.0,\n",
            "         164: 1.0,\n",
            "         165: 9.0,\n",
            "         166: nan,\n",
            "         167: 45.0,\n",
            "         168: nan,\n",
            "         169: 28.0,\n",
            "         170: 61.0,\n",
            "         171: 4.0,\n",
            "         172: 1.0,\n",
            "         173: 21.0,\n",
            "         174: 56.0,\n",
            "         175: 18.0,\n",
            "         176: nan,\n",
            "         177: 50.0,\n",
            "         178: 30.0,\n",
            "         179: 36.0,\n",
            "         180: nan,\n",
            "         181: nan,\n",
            "         182: 9.0,\n",
            "         183: 1.0,\n",
            "         184: 4.0,\n",
            "         185: nan,\n",
            "         186: nan,\n",
            "         187: 45.0,\n",
            "         188: 40.0,\n",
            "         189: 36.0,\n",
            "         190: 32.0,\n",
            "         191: 19.0,\n",
            "         192: 19.0,\n",
            "         193: 3.0,\n",
            "         194: 44.0,\n",
            "         195: 58.0,\n",
            "         196: nan,\n",
            "         197: 42.0,\n",
            "         198: nan,\n",
            "         199: 24.0,\n",
            "         200: 28.0,\n",
            "         201: nan,\n",
            "         202: 34.0,\n",
            "         203: 45.5,\n",
            "         204: 18.0,\n",
            "         205: 2.0,\n",
            "         206: 32.0,\n",
            "         207: 26.0,\n",
            "         208: 16.0,\n",
            "         209: 40.0,\n",
            "         210: 24.0,\n",
            "         211: 35.0,\n",
            "         212: 22.0,\n",
            "         213: 30.0,\n",
            "         214: nan,\n",
            "         215: 31.0,\n",
            "         216: 27.0,\n",
            "         217: 42.0,\n",
            "         218: 32.0,\n",
            "         219: 30.0,\n",
            "         220: 16.0,\n",
            "         221: 27.0,\n",
            "         222: 51.0,\n",
            "         223: nan,\n",
            "         224: 38.0,\n",
            "         225: 22.0,\n",
            "         226: 19.0,\n",
            "         227: 20.5,\n",
            "         228: 18.0,\n",
            "         229: nan,\n",
            "         230: 35.0,\n",
            "         231: 29.0,\n",
            "         232: 59.0,\n",
            "         233: 5.0,\n",
            "         234: 24.0,\n",
            "         235: nan,\n",
            "         236: 44.0,\n",
            "         237: 8.0,\n",
            "         238: 19.0,\n",
            "         239: 33.0,\n",
            "         240: nan,\n",
            "         241: nan,\n",
            "         242: 29.0,\n",
            "         243: 22.0,\n",
            "         244: 30.0,\n",
            "         245: 44.0,\n",
            "         246: 25.0,\n",
            "         247: 24.0,\n",
            "         248: 37.0,\n",
            "         249: 54.0,\n",
            "         250: nan,\n",
            "         251: 29.0,\n",
            "         252: 62.0,\n",
            "         253: 30.0,\n",
            "         254: 41.0,\n",
            "         255: 29.0,\n",
            "         256: nan,\n",
            "         257: 30.0,\n",
            "         258: 35.0,\n",
            "         259: 50.0,\n",
            "         260: nan,\n",
            "         261: 3.0,\n",
            "         262: 52.0,\n",
            "         263: 40.0,\n",
            "         264: nan,\n",
            "         265: 36.0,\n",
            "         266: 16.0,\n",
            "         267: 25.0,\n",
            "         268: 58.0,\n",
            "         269: 35.0,\n",
            "         270: nan,\n",
            "         271: 25.0,\n",
            "         272: 41.0,\n",
            "         273: 37.0,\n",
            "         274: nan,\n",
            "         275: 63.0,\n",
            "         276: 45.0,\n",
            "         277: nan,\n",
            "         278: 7.0,\n",
            "         279: 35.0,\n",
            "         280: 65.0,\n",
            "         281: 28.0,\n",
            "         282: 16.0,\n",
            "         283: 19.0,\n",
            "         284: nan,\n",
            "         285: 33.0,\n",
            "         286: 30.0,\n",
            "         287: 22.0,\n",
            "         288: 42.0,\n",
            "         289: 22.0,\n",
            "         290: 26.0,\n",
            "         291: 19.0,\n",
            "         292: 36.0,\n",
            "         293: 24.0,\n",
            "         294: 24.0,\n",
            "         295: nan,\n",
            "         296: 23.5,\n",
            "         297: 2.0,\n",
            "         298: nan,\n",
            "         299: 50.0,\n",
            "         300: nan,\n",
            "         301: nan,\n",
            "         302: 19.0,\n",
            "         303: nan,\n",
            "         304: nan,\n",
            "         305: 0.92,\n",
            "         306: nan,\n",
            "         307: 17.0,\n",
            "         308: 30.0,\n",
            "         309: 30.0,\n",
            "         310: 24.0,\n",
            "         311: 18.0,\n",
            "         312: 26.0,\n",
            "         313: 28.0,\n",
            "         314: 43.0,\n",
            "         315: 26.0,\n",
            "         316: 24.0,\n",
            "         317: 54.0,\n",
            "         318: 31.0,\n",
            "         319: 40.0,\n",
            "         320: 22.0,\n",
            "         321: 27.0,\n",
            "         322: 30.0,\n",
            "         323: 22.0,\n",
            "         324: nan,\n",
            "         325: 36.0,\n",
            "         326: 61.0,\n",
            "         327: 36.0,\n",
            "         328: 31.0,\n",
            "         329: 16.0,\n",
            "         330: nan,\n",
            "         331: 45.5,\n",
            "         332: 38.0,\n",
            "         333: 16.0,\n",
            "         334: nan,\n",
            "         335: nan,\n",
            "         336: 29.0,\n",
            "         337: 41.0,\n",
            "         338: 45.0,\n",
            "         339: 45.0,\n",
            "         340: 2.0,\n",
            "         341: 24.0,\n",
            "         342: 28.0,\n",
            "         343: 25.0,\n",
            "         344: 36.0,\n",
            "         345: 24.0,\n",
            "         346: 40.0,\n",
            "         347: nan,\n",
            "         348: 3.0,\n",
            "         349: 42.0,\n",
            "         350: 23.0,\n",
            "         351: nan,\n",
            "         352: 15.0,\n",
            "         353: 25.0,\n",
            "         354: nan,\n",
            "         355: 28.0,\n",
            "         356: 22.0,\n",
            "         357: 38.0,\n",
            "         358: nan,\n",
            "         359: nan,\n",
            "         360: 40.0,\n",
            "         361: 29.0,\n",
            "         362: 45.0,\n",
            "         363: 35.0,\n",
            "         364: nan,\n",
            "         365: 30.0,\n",
            "         366: 60.0,\n",
            "         367: nan,\n",
            "         368: nan,\n",
            "         369: 24.0,\n",
            "         370: 25.0,\n",
            "         371: 18.0,\n",
            "         372: 19.0,\n",
            "         373: 22.0,\n",
            "         374: 3.0,\n",
            "         375: nan,\n",
            "         376: 22.0,\n",
            "         377: 27.0,\n",
            "         378: 20.0,\n",
            "         379: 19.0,\n",
            "         380: 42.0,\n",
            "         381: 1.0,\n",
            "         382: 32.0,\n",
            "         383: 35.0,\n",
            "         384: nan,\n",
            "         385: 18.0,\n",
            "         386: 1.0,\n",
            "         387: 36.0,\n",
            "         388: nan,\n",
            "         389: 17.0,\n",
            "         390: 36.0,\n",
            "         391: 21.0,\n",
            "         392: 28.0,\n",
            "         393: 23.0,\n",
            "         394: 24.0,\n",
            "         395: 22.0,\n",
            "         396: 31.0,\n",
            "         397: 46.0,\n",
            "         398: 23.0,\n",
            "         399: 28.0,\n",
            "         400: 39.0,\n",
            "         401: 26.0,\n",
            "         402: 21.0,\n",
            "         403: 28.0,\n",
            "         404: 20.0,\n",
            "         405: 34.0,\n",
            "         406: 51.0,\n",
            "         407: 3.0,\n",
            "         408: 21.0,\n",
            "         409: nan,\n",
            "         410: nan,\n",
            "         411: nan,\n",
            "         412: 33.0,\n",
            "         413: nan,\n",
            "         414: 44.0,\n",
            "         415: nan,\n",
            "         416: 34.0,\n",
            "         417: 18.0,\n",
            "         418: 30.0,\n",
            "         419: 10.0,\n",
            "         420: nan,\n",
            "         421: 21.0,\n",
            "         422: 29.0,\n",
            "         423: 28.0,\n",
            "         424: 18.0,\n",
            "         425: nan,\n",
            "         426: 28.0,\n",
            "         427: 19.0,\n",
            "         428: nan,\n",
            "         429: 32.0,\n",
            "         430: 28.0,\n",
            "         431: nan,\n",
            "         432: 42.0,\n",
            "         433: 17.0,\n",
            "         434: 50.0,\n",
            "         435: 14.0,\n",
            "         436: 21.0,\n",
            "         437: 24.0,\n",
            "         438: 64.0,\n",
            "         439: 31.0,\n",
            "         440: 45.0,\n",
            "         441: 20.0,\n",
            "         442: 25.0,\n",
            "         443: 28.0,\n",
            "         444: nan,\n",
            "         445: 4.0,\n",
            "         446: 13.0,\n",
            "         447: 34.0,\n",
            "         448: 5.0,\n",
            "         449: 52.0,\n",
            "         450: 36.0,\n",
            "         451: nan,\n",
            "         452: 30.0,\n",
            "         453: 49.0,\n",
            "         454: nan,\n",
            "         455: 29.0,\n",
            "         456: 65.0,\n",
            "         457: nan,\n",
            "         458: 50.0,\n",
            "         459: nan,\n",
            "         460: 48.0,\n",
            "         461: 34.0,\n",
            "         462: 47.0,\n",
            "         463: 48.0,\n",
            "         464: nan,\n",
            "         465: 38.0,\n",
            "         466: nan,\n",
            "         467: 56.0,\n",
            "         468: nan,\n",
            "         469: 0.75,\n",
            "         470: nan,\n",
            "         471: 38.0,\n",
            "         472: 33.0,\n",
            "         473: 23.0,\n",
            "         474: 22.0,\n",
            "         475: nan,\n",
            "         476: 34.0,\n",
            "         477: 29.0,\n",
            "         478: 22.0,\n",
            "         479: 2.0,\n",
            "         480: 9.0,\n",
            "         481: nan,\n",
            "         482: 50.0,\n",
            "         483: 63.0,\n",
            "         484: 25.0,\n",
            "         485: nan,\n",
            "         486: 35.0,\n",
            "         487: 58.0,\n",
            "         488: 30.0,\n",
            "         489: 9.0,\n",
            "         490: nan,\n",
            "         491: 21.0,\n",
            "         492: 55.0,\n",
            "         493: 71.0,\n",
            "         494: 21.0,\n",
            "         495: nan,\n",
            "         496: 54.0,\n",
            "         497: nan,\n",
            "         498: 25.0,\n",
            "         499: 24.0,\n",
            "         500: 17.0,\n",
            "         501: 21.0,\n",
            "         502: nan,\n",
            "         503: 37.0,\n",
            "         504: 16.0,\n",
            "         505: 18.0,\n",
            "         506: 33.0,\n",
            "         507: nan,\n",
            "         508: 28.0,\n",
            "         509: 26.0,\n",
            "         510: 29.0,\n",
            "         511: nan,\n",
            "         512: 36.0,\n",
            "         513: 54.0,\n",
            "         514: 24.0,\n",
            "         515: 47.0,\n",
            "         516: 34.0,\n",
            "         517: nan,\n",
            "         518: 36.0,\n",
            "         519: 32.0,\n",
            "         520: 30.0,\n",
            "         521: 22.0,\n",
            "         522: nan,\n",
            "         523: 44.0,\n",
            "         524: nan,\n",
            "         525: 40.5,\n",
            "         526: 50.0,\n",
            "         527: nan,\n",
            "         528: 39.0,\n",
            "         529: 23.0,\n",
            "         530: 2.0,\n",
            "         531: nan,\n",
            "         532: 17.0,\n",
            "         533: nan,\n",
            "         534: 30.0,\n",
            "         535: 7.0,\n",
            "         536: 45.0,\n",
            "         537: 30.0,\n",
            "         538: nan,\n",
            "         539: 22.0,\n",
            "         540: 36.0,\n",
            "         541: 9.0,\n",
            "         542: 11.0,\n",
            "         543: 32.0,\n",
            "         544: 50.0,\n",
            "         545: 64.0,\n",
            "         546: 19.0,\n",
            "         547: nan,\n",
            "         548: 33.0,\n",
            "         549: 8.0,\n",
            "         550: 17.0,\n",
            "         551: 27.0,\n",
            "         552: nan,\n",
            "         553: 22.0,\n",
            "         554: 22.0,\n",
            "         555: 62.0,\n",
            "         556: 48.0,\n",
            "         557: nan,\n",
            "         558: 39.0,\n",
            "         559: 36.0,\n",
            "         560: nan,\n",
            "         561: 40.0,\n",
            "         562: 28.0,\n",
            "         563: nan,\n",
            "         564: nan,\n",
            "         565: 24.0,\n",
            "         566: 19.0,\n",
            "         567: 29.0,\n",
            "         568: nan,\n",
            "         569: 32.0,\n",
            "         570: 62.0,\n",
            "         571: 53.0,\n",
            "         572: 36.0,\n",
            "         573: nan,\n",
            "         574: 16.0,\n",
            "         575: 19.0,\n",
            "         576: 34.0,\n",
            "         577: 39.0,\n",
            "         578: nan,\n",
            "         579: 32.0,\n",
            "         580: 25.0,\n",
            "         581: 39.0,\n",
            "         582: 54.0,\n",
            "         583: 36.0,\n",
            "         584: nan,\n",
            "         585: 18.0,\n",
            "         586: 47.0,\n",
            "         587: 60.0,\n",
            "         588: 22.0,\n",
            "         589: nan,\n",
            "         590: 35.0,\n",
            "         591: 52.0,\n",
            "         592: 47.0,\n",
            "         593: nan,\n",
            "         594: 37.0,\n",
            "         595: 36.0,\n",
            "         596: nan,\n",
            "         597: 49.0,\n",
            "         598: nan,\n",
            "         599: 49.0,\n",
            "         600: 24.0,\n",
            "         601: nan,\n",
            "         602: nan,\n",
            "         603: 44.0,\n",
            "         604: 35.0,\n",
            "         605: 36.0,\n",
            "         606: 30.0,\n",
            "         607: 27.0,\n",
            "         608: 22.0,\n",
            "         609: 40.0,\n",
            "         610: 39.0,\n",
            "         611: nan,\n",
            "         612: nan,\n",
            "         613: nan,\n",
            "         614: 35.0,\n",
            "         615: 24.0,\n",
            "         616: 34.0,\n",
            "         617: 26.0,\n",
            "         618: 4.0,\n",
            "         619: 26.0,\n",
            "         620: 27.0,\n",
            "         621: 42.0,\n",
            "         622: 20.0,\n",
            "         623: 21.0,\n",
            "         624: 21.0,\n",
            "         625: 61.0,\n",
            "         626: 57.0,\n",
            "         627: 21.0,\n",
            "         628: 26.0,\n",
            "         629: nan,\n",
            "         630: 80.0,\n",
            "         631: 51.0,\n",
            "         632: 32.0,\n",
            "         633: nan,\n",
            "         634: 9.0,\n",
            "         635: 28.0,\n",
            "         636: 32.0,\n",
            "         637: 31.0,\n",
            "         638: 41.0,\n",
            "         639: nan,\n",
            "         640: 20.0,\n",
            "         641: 24.0,\n",
            "         642: 2.0,\n",
            "         643: nan,\n",
            "         644: 0.75,\n",
            "         645: 48.0,\n",
            "         646: 19.0,\n",
            "         647: 56.0,\n",
            "         648: nan,\n",
            "         649: 23.0,\n",
            "         650: nan,\n",
            "         651: 18.0,\n",
            "         652: 21.0,\n",
            "         653: nan,\n",
            "         654: 18.0,\n",
            "         655: 24.0,\n",
            "         656: nan,\n",
            "         657: 32.0,\n",
            "         658: 23.0,\n",
            "         659: 58.0,\n",
            "         660: 50.0,\n",
            "         661: 40.0,\n",
            "         662: 47.0,\n",
            "         663: 36.0,\n",
            "         664: 20.0,\n",
            "         665: 32.0,\n",
            "         666: 25.0,\n",
            "         667: nan,\n",
            "         668: 43.0,\n",
            "         669: nan,\n",
            "         670: 40.0,\n",
            "         671: 31.0,\n",
            "         672: 70.0,\n",
            "         673: 31.0,\n",
            "         674: nan,\n",
            "         675: 18.0,\n",
            "         676: 24.5,\n",
            "         677: 18.0,\n",
            "         678: 43.0,\n",
            "         679: 36.0,\n",
            "         680: nan,\n",
            "         681: 27.0,\n",
            "         682: 20.0,\n",
            "         683: 14.0,\n",
            "         684: 60.0,\n",
            "         685: 25.0,\n",
            "         686: 14.0,\n",
            "         687: 19.0,\n",
            "         688: 18.0,\n",
            "         689: 15.0,\n",
            "         690: 31.0,\n",
            "         691: 4.0,\n",
            "         692: nan,\n",
            "         693: 25.0,\n",
            "         694: 60.0,\n",
            "         695: 52.0,\n",
            "         696: 44.0,\n",
            "         697: nan,\n",
            "         698: 49.0,\n",
            "         699: 42.0,\n",
            "         700: 18.0,\n",
            "         701: 35.0,\n",
            "         702: 18.0,\n",
            "         703: 25.0,\n",
            "         704: 26.0,\n",
            "         705: 39.0,\n",
            "         706: 45.0,\n",
            "         707: 42.0,\n",
            "         708: 22.0,\n",
            "         709: nan,\n",
            "         710: 24.0,\n",
            "         711: nan,\n",
            "         712: 48.0,\n",
            "         713: 29.0,\n",
            "         714: 52.0,\n",
            "         715: 19.0,\n",
            "         716: 38.0,\n",
            "         717: 27.0,\n",
            "         718: nan,\n",
            "         719: 33.0,\n",
            "         720: 6.0,\n",
            "         721: 17.0,\n",
            "         722: 34.0,\n",
            "         723: 50.0,\n",
            "         724: 27.0,\n",
            "         725: 20.0,\n",
            "         726: 30.0,\n",
            "         727: nan,\n",
            "         728: 25.0,\n",
            "         729: 25.0,\n",
            "         730: 29.0,\n",
            "         731: 11.0,\n",
            "         732: nan,\n",
            "         733: 23.0,\n",
            "         734: 23.0,\n",
            "         735: 28.5,\n",
            "         736: 48.0,\n",
            "         737: 35.0,\n",
            "         738: nan,\n",
            "         739: nan,\n",
            "         740: nan,\n",
            "         741: 36.0,\n",
            "         742: 21.0,\n",
            "         743: 24.0,\n",
            "         744: 31.0,\n",
            "         745: 70.0,\n",
            "         746: 16.0,\n",
            "         747: 30.0,\n",
            "         748: 19.0,\n",
            "         749: 31.0,\n",
            "         750: 4.0,\n",
            "         751: 6.0,\n",
            "         752: 33.0,\n",
            "         753: 23.0,\n",
            "         754: 48.0,\n",
            "         755: 0.67,\n",
            "         756: 28.0,\n",
            "         757: 18.0,\n",
            "         758: 34.0,\n",
            "         759: 33.0,\n",
            "         760: nan,\n",
            "         761: 41.0,\n",
            "         762: 20.0,\n",
            "         763: 36.0,\n",
            "         764: 16.0,\n",
            "         765: 51.0,\n",
            "         766: nan,\n",
            "         767: 30.5,\n",
            "         768: nan,\n",
            "         769: 32.0,\n",
            "         770: 24.0,\n",
            "         771: 48.0,\n",
            "         772: 57.0,\n",
            "         773: nan,\n",
            "         774: 54.0,\n",
            "         775: 18.0,\n",
            "         776: nan,\n",
            "         777: 5.0,\n",
            "         778: nan,\n",
            "         779: 43.0,\n",
            "         780: 13.0,\n",
            "         781: 17.0,\n",
            "         782: 29.0,\n",
            "         783: nan,\n",
            "         784: 25.0,\n",
            "         785: 25.0,\n",
            "         786: 18.0,\n",
            "         787: 8.0,\n",
            "         788: 1.0,\n",
            "         789: 46.0,\n",
            "         790: nan,\n",
            "         791: 16.0,\n",
            "         792: nan,\n",
            "         793: nan,\n",
            "         794: 25.0,\n",
            "         795: 39.0,\n",
            "         796: 49.0,\n",
            "         797: 31.0,\n",
            "         798: 30.0,\n",
            "         799: 30.0,\n",
            "         800: 34.0,\n",
            "         801: 31.0,\n",
            "         802: 11.0,\n",
            "         803: 0.42,\n",
            "         804: 27.0,\n",
            "         805: 31.0,\n",
            "         806: 39.0,\n",
            "         807: 18.0,\n",
            "         808: 39.0,\n",
            "         809: 33.0,\n",
            "         810: 26.0,\n",
            "         811: 39.0,\n",
            "         812: 35.0,\n",
            "         813: 6.0,\n",
            "         814: 30.5,\n",
            "         815: nan,\n",
            "         816: 23.0,\n",
            "         817: 31.0,\n",
            "         818: 43.0,\n",
            "         819: 10.0,\n",
            "         820: 52.0,\n",
            "         821: 27.0,\n",
            "         822: 38.0,\n",
            "         823: 27.0,\n",
            "         824: 2.0,\n",
            "         825: nan,\n",
            "         826: nan,\n",
            "         827: 1.0,\n",
            "         828: nan,\n",
            "         829: 62.0,\n",
            "         830: 15.0,\n",
            "         831: 0.83,\n",
            "         832: nan,\n",
            "         833: 23.0,\n",
            "         834: 18.0,\n",
            "         835: 39.0,\n",
            "         836: 21.0,\n",
            "         837: nan,\n",
            "         838: 32.0,\n",
            "         839: nan,\n",
            "         840: 20.0,\n",
            "         841: 16.0,\n",
            "         842: 30.0,\n",
            "         843: 34.5,\n",
            "         844: 17.0,\n",
            "         845: 42.0,\n",
            "         846: nan,\n",
            "         847: 35.0,\n",
            "         848: 28.0,\n",
            "         849: nan,\n",
            "         850: 4.0,\n",
            "         851: 74.0,\n",
            "         852: 9.0,\n",
            "         853: 16.0,\n",
            "         854: 44.0,\n",
            "         855: 18.0,\n",
            "         856: 45.0,\n",
            "         857: 51.0,\n",
            "         858: 24.0,\n",
            "         859: nan,\n",
            "         860: 41.0,\n",
            "         861: 21.0,\n",
            "         862: 48.0,\n",
            "         863: nan,\n",
            "         864: 24.0,\n",
            "         865: 42.0,\n",
            "         866: 27.0,\n",
            "         867: 31.0,\n",
            "         868: nan,\n",
            "         869: 4.0,\n",
            "         870: 26.0,\n",
            "         871: 47.0,\n",
            "         872: 33.0,\n",
            "         873: 47.0,\n",
            "         874: 28.0,\n",
            "         875: 15.0,\n",
            "         876: 20.0,\n",
            "         877: 19.0,\n",
            "         878: nan,\n",
            "         879: 56.0,\n",
            "         880: 25.0,\n",
            "         881: 33.0,\n",
            "         882: 22.0,\n",
            "         883: 28.0,\n",
            "         884: 25.0,\n",
            "         885: 39.0,\n",
            "         886: 27.0,\n",
            "         887: 19.0,\n",
            "         888: nan,\n",
            "         889: 26.0,\n",
            "         890: 32.0}}\n"
          ]
        }
      ],
      "source": [
        "# 열 작업 예시입니다.\n",
        "df_query = \"Age column 을 조회해 주세요.\"\n",
        "\n",
        "\n",
        "# 프롬프트 템플릿을 설정합니다.\n",
        "prompt = PromptTemplate(\n",
        "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
        "    input_variables=[\"query\"],  # 입력 변수 설정\n",
        "    partial_variables={\n",
        "        \"format_instructions\": parser.get_format_instructions()\n",
        "    },  # 부분 변수 설정\n",
        ")\n",
        "\n",
        "# 체인 생성\n",
        "chain = prompt | model | parser\n",
        "\n",
        "# 체인 실행\n",
        "parser_output = chain.invoke({\"query\": df_query})\n",
        "\n",
        "# 출력\n",
        "format_parser_output(parser_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c52c65a-7360-44e5-ba4c-a0656186c83d",
      "metadata": {
        "id": "2c52c65a-7360-44e5-ba4c-a0656186c83d",
        "outputId": "3d3e0cf4-dfb1-41bd-d24e-d27c3ea4f423"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'0': {'Age': 22.0,\n",
            "       'Cabin': nan,\n",
            "       'Embarked': 'S',\n",
            "       'Fare': 7.25,\n",
            "       'Gender': 'male',\n",
            "       'Name': 'Braund, '\n",
            "               'Mr. '\n",
            "               'Owen '\n",
            "               'Harris',\n",
            "       'Parch': 0,\n",
            "       'PassengerId': 1,\n",
            "       'Pclass': 3,\n",
            "       'SibSp': 1,\n",
            "       'Survived': 0,\n",
            "       'Ticket': 'A/5 '\n",
            "                 '21171'}}\n"
          ]
        }
      ],
      "source": [
        "# 행 조회 예시입니다.\n",
        "df_query = \"Retrieve the first row.\"\n",
        "\n",
        "# 체인 실행\n",
        "parser_output = chain.invoke({\"query\": df_query})\n",
        "\n",
        "# 결과 출력\n",
        "format_parser_output(parser_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4174ba3-bb4d-4c6c-9d83-e7ab21d7e8be",
      "metadata": {
        "id": "b4174ba3-bb4d-4c6c-9d83-e7ab21d7e8be",
        "outputId": "44b98921-e60a-405d-8ba2-bcb1eed470f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "31.2"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# row 0 ~ 4의 평균 나이를 구합니다.\n",
        "df[\"Age\"].head().mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc4338ba-6acf-488c-90dd-89b574ab3e75",
      "metadata": {
        "id": "fc4338ba-6acf-488c-90dd-89b574ab3e75",
        "outputId": "14ff9963-bbd4-4170-e7e1-1498748e17f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'mean': 31.2}\n"
          ]
        }
      ],
      "source": [
        "# 임의의 Pandas DataFrame 작업 예시, 행의 수를 제한합니다.\n",
        "df_query = \"Retrieve the average of the Ages from row 0 to 4.\"\n",
        "\n",
        "# 체인 실행\n",
        "parser_output = chain.invoke({\"query\": df_query})\n",
        "\n",
        "# 결과 출력\n",
        "print(parser_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3baf64e9-f408-4ef3-8c5b-73bd873fc2df",
      "metadata": {
        "id": "3baf64e9-f408-4ef3-8c5b-73bd873fc2df"
      },
      "source": [
        "요금(Fare) 에 대한 평균 가격을 산정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "801d6185-114c-4bd9-ab02-db58eed033cf",
      "metadata": {
        "id": "801d6185-114c-4bd9-ab02-db58eed033cf",
        "outputId": "ec02431a-776e-43c6-d01e-ea028a4f53cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'mean': 32.204207968574636}\n"
          ]
        }
      ],
      "source": [
        "# 잘못 형식화된 쿼리의 예시입니다.\n",
        "df_query = \"Calculate average `Fare` rate.\"\n",
        "\n",
        "# 체인 실행\n",
        "parser_output = chain.invoke({\"query\": df_query})\n",
        "\n",
        "# 결과 출력\n",
        "print(parser_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c85bf61c-ddab-42e2-a629-7b39f256d98e",
      "metadata": {
        "id": "c85bf61c-ddab-42e2-a629-7b39f256d98e",
        "outputId": "97fb8848-8cee-489e-e849-495b0701764f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "32.204207968574636"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 결과 검증\n",
        "df[\"Fare\"].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5efc4a28-6ca3-422d-a6cf-c0398a5d23e5",
      "metadata": {
        "id": "5efc4a28-6ca3-422d-a6cf-c0398a5d23e5"
      },
      "source": [
        "#### 날짜 형식 출력 파서(DatetimeOutputParser)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cbd3d9b-3d58-4873-b9dc-e900bc1c8dd4",
      "metadata": {
        "id": "5cbd3d9b-3d58-4873-b9dc-e900bc1c8dd4",
        "outputId": "362b0466-1a33-44ce-df9b-1a0838ad6ab9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['question'], input_types={}, partial_variables={'format_instructions': \"Write a datetime string that matches the following pattern: '%Y-%m-%d'.\\n\\nExamples: 1609-09-22, 9-01-08, 1106-09-10\\n\\nReturn ONLY this string, no other words!\"}, template='Answer the users question:\\n\\n#Format Instructions: \\n{format_instructions}\\n\\n#Question: \\n{question}\\n\\n#Answer:')"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.output_parsers import DatetimeOutputParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# 날짜 및 시간 출력 파서\n",
        "output_parser = DatetimeOutputParser()\n",
        "output_parser.format = \"%Y-%m-%d\"\n",
        "\n",
        "# 사용자 질문에 대한 답변 템플릿\n",
        "template = \"\"\"Answer the users question:\\n\\n#Format Instructions: \\n{format_instructions}\\n\\n#Question: \\n{question}\\n\\n#Answer:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "    template,\n",
        "    partial_variables={\n",
        "        \"format_instructions\": output_parser.get_format_instructions()\n",
        "    },  # 지침을 템플릿에 적용\n",
        ")\n",
        "\n",
        "# 프롬프트 내용을 출력\n",
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f2fb17e-4603-486f-8bc0-d32394026508",
      "metadata": {
        "id": "2f2fb17e-4603-486f-8bc0-d32394026508"
      },
      "outputs": [],
      "source": [
        "# Chain 을 생성합니다.\n",
        "chain = prompt | ChatOpenAI() | output_parser\n",
        "\n",
        "# 체인을 호출하여 질문에 대한 답변을 받습니다.\n",
        "output = chain.invoke({\"question\": \"Google 이 창업한 연도는?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16501395-24a1-49cd-867b-0de5797604bb",
      "metadata": {
        "id": "16501395-24a1-49cd-867b-0de5797604bb",
        "outputId": "6fc63cab-e406-486b-e0d3-9ca42d9cdf93"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'1998-09-04'"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 결과를 문자열로 변환\n",
        "output.strftime(\"%Y-%m-%d\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6b77106-efe9-4224-b6a0-2d79351dede3",
      "metadata": {
        "id": "c6b77106-efe9-4224-b6a0-2d79351dede3"
      },
      "source": [
        "날짜와 시간 형식의 결과 받아보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca2fa834-f60f-4a26-bd38-21d847c5328c",
      "metadata": {
        "id": "ca2fa834-f60f-4a26-bd38-21d847c5328c",
        "outputId": "b48112ed-7d62-49cd-b3d3-7607e011f459"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "출력된 날짜 형식을 파싱할 수 없습니다: iPhone 8는 2017년 9월 22일에 출시되었습니다.\n"
          ]
        }
      ],
      "source": [
        "from langchain import PromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage, SystemMessage\n",
        "from datetime import datetime  # datetime 모듈 가져오기\n",
        "\n",
        "# Chat 모델 인스턴스 생성\n",
        "chat = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "\n",
        "# 프롬프트 템플릿 생성\n",
        "prompt = PromptTemplate.from_template(\"{product}의 출시일을 알려주세요\")\n",
        "\n",
        "# iPhone8의 출시일을 물어보는 프롬프트 생성\n",
        "formatted_prompt = prompt.format(product=\"iPhone8\")\n",
        "\n",
        "# 모델에게 날짜 형식을 지정하도록 지시하는 시스템 메시지\n",
        "instructions = \"날짜를 'YYYY-MM-DD' 형식으로만 답변해 주세요.\"\n",
        "\n",
        "# 메시지 리스트 생성\n",
        "messages = [\n",
        "    SystemMessage(content=instructions),  # 시스템 메시지로 모델에 지시사항 추가\n",
        "    HumanMessage(content=formatted_prompt),  # 사용자 입력 메시지 추가\n",
        "]\n",
        "\n",
        "# 모델 예측 수행\n",
        "result = chat(messages)\n",
        "\n",
        "# 출력 결과를 분석하여 날짜 및 시간 형식으로 변환\n",
        "try:\n",
        "    output_date = datetime.strptime(result.content.strip(), \"%Y-%m-%d\")\n",
        "    print(\"출시일:\", output_date.date())  # YYYY-MM-DD 형식으로 출력\n",
        "except ValueError:\n",
        "    print(\"출력된 날짜 형식을 파싱할 수 없습니다:\", result.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eac225f5-d039-4221-9ab2-6bf05bd63ca8",
      "metadata": {
        "id": "eac225f5-d039-4221-9ab2-6bf05bd63ca8"
      },
      "source": [
        "출력 형식을 직접 정의하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "742ff301-10aa-40ec-993f-b5dce57af5cc",
      "metadata": {
        "id": "742ff301-10aa-40ec-993f-b5dce57af5cc",
        "outputId": "fa1e5afc-57ae-4013-bac3-a5a7654f0b0a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nh/miniconda3/envs/py310_langchain/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in Smartphone has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "모델명: Samsung Galaxy S21\n",
            "화면 크기: 6.5인치\n",
            "OS: Android 11\n",
            "스마트폰 출시일: 2021-08-20\n"
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.schema import HumanMessage\n",
        "from pydantic import BaseModel, Field, field_validator  # validator 대신 field_validator 사용\n",
        "\n",
        "chat = ChatOpenAI()\n",
        "\n",
        "class Smartphone(BaseModel):  # Pydantic의 모델을 정의\n",
        "    release_date: str = Field(description=\"스마트폰 출시일\")  # Field를 사용해 설명을 추가\n",
        "    screen_inches: float = Field(description=\"스마트폰의 화면 크기(인치)\")\n",
        "    os_installed: str = Field(description=\"스마트폰에 설치된 OS\")\n",
        "    model_name: str = Field(description=\"스마트폰 모델명\")\n",
        "\n",
        "    @field_validator(\"screen_inches\")  # validator 대신 field_validator를 사용\n",
        "    def validate_screen_inches(cls, value):  # 검증할 필드와 값을 validator의 인수로 전달\n",
        "        if value <= 0:  # screen_inches가 0 이하인 경우 에러를 반환\n",
        "            raise ValueError(\"Screen inches must be a positive number\")\n",
        "        return value\n",
        "\n",
        "# PydanticOutputParser를 Smartphone 모델로 초기화\n",
        "parser = PydanticOutputParser(pydantic_object=Smartphone)\n",
        "\n",
        "# Chat model에 HumanMessage를 전달해 문장을 생성\n",
        "result = chat([\n",
        "    HumanMessage(content=\"안드로이드 스마트폰 1개를 꼽아주세요\"),\n",
        "    HumanMessage(content=parser.get_format_instructions())\n",
        "])\n",
        "\n",
        "# PydanticOutputParser를 사용해 문장을 파싱\n",
        "parsed_result = parser.parse(result.content)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"모델명: {parsed_result.model_name}\")\n",
        "print(f\"화면 크기: {parsed_result.screen_inches}인치\")\n",
        "print(f\"OS: {parsed_result.os_installed}\")\n",
        "print(f\"스마트폰 출시일: {parsed_result.release_date}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7d8fb8d-55b6-4749-bf2e-6d66fb199f26",
      "metadata": {
        "id": "a7d8fb8d-55b6-4749-bf2e-6d66fb199f26"
      },
      "source": [
        "잘못된 결과가 반환될 때 수정 지시"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dd0b04b-da0e-4eb4-aafd-016980e7c135",
      "metadata": {
        "id": "2dd0b04b-da0e-4eb4-aafd-016980e7c135",
        "outputId": "c9c8ffaa-7f3f-4552-9925-98ab2a69c22a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nh/miniconda3/envs/py310_langchain/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in Smartphone has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "모델명: Samsung Galaxy S21\n",
            "화면 크기: 6.7인치\n",
            "OS: Android 11\n",
            "스마트폰 출시일: 2021-10-15\n"
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.output_parsers import OutputFixingParser, PydanticOutputParser\n",
        "from langchain.schema import HumanMessage\n",
        "from pydantic import BaseModel, Field, field_validator  # Pydantic v2 스타일로 변경\n",
        "\n",
        "chat = ChatOpenAI()\n",
        "\n",
        "class Smartphone(BaseModel):\n",
        "    release_date: str = Field(description=\"스마트폰 출시일\")\n",
        "    screen_inches: float = Field(description=\"스마트폰의 화면 크기(인치)\")\n",
        "    os_installed: str = Field(description=\"스마트폰에 설치된 OS\")\n",
        "    model_name: str = Field(description=\"스마트폰 모델명\")\n",
        "\n",
        "    # Pydantic v2 스타일의 validator 사용\n",
        "    @field_validator(\"screen_inches\")\n",
        "    def validate_screen_inches(cls, value):\n",
        "        if value <= 0:\n",
        "            raise ValueError(\"Screen inches must be a positive number\")\n",
        "        return value\n",
        "\n",
        "# PydanticOutputParser를 Smartphone 모델로 초기화\n",
        "parser = OutputFixingParser.from_llm(\n",
        "    parser=PydanticOutputParser(pydantic_object=Smartphone),  # Pydantic 모델로 파서 설정\n",
        "    llm=chat  # 수정에 사용할 언어 모델 설정\n",
        ")\n",
        "\n",
        "# Chat model에 HumanMessage를 전달해 문장을 생성\n",
        "result = chat([\n",
        "    HumanMessage(content=\"안드로이드 스마트폰 1개를 꼽아주세요\"),\n",
        "    HumanMessage(content=parser.get_format_instructions())\n",
        "])\n",
        "\n",
        "# PydanticOutputParser를 사용해 문장을 파싱\n",
        "parsed_result = parser.parse(result.content)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"모델명: {parsed_result.model_name}\")\n",
        "print(f\"화면 크기: {parsed_result.screen_inches}인치\")\n",
        "print(f\"OS: {parsed_result.os_installed}\")\n",
        "print(f\"스마트폰 출시일: {parsed_result.release_date}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py3_10_langchain",
      "language": "python",
      "name": "py3_10_langchain"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}